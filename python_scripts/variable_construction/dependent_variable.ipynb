{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import daily stock prices\n",
    "\n",
    "df_raw = pd.read_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/stock_level_data/stock_level_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>price</th>\n",
       "      <th>Daily_Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>-0.017822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>4.920000</td>\n",
       "      <td>-0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>4.780000</td>\n",
       "      <td>-0.028455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>-0.029289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>4.570000</td>\n",
       "      <td>-0.015086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>467.319907</td>\n",
       "      <td>-0.004237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>467.883798</td>\n",
       "      <td>0.001207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>468.655209</td>\n",
       "      <td>0.001649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>466.683790</td>\n",
       "      <td>-0.004207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>473.362743</td>\n",
       "      <td>0.014312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3166148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           stock_RIC       price  Daily_Returns\n",
       "date                                           \n",
       "2010-01-04    1U1.DE    4.960000      -0.017822\n",
       "2010-01-05    1U1.DE    4.920000      -0.008065\n",
       "2010-01-06    1U1.DE    4.780000      -0.028455\n",
       "2010-01-07    1U1.DE    4.640000      -0.029289\n",
       "2010-01-08    1U1.DE    4.570000      -0.015086\n",
       "...              ...         ...            ...\n",
       "2023-12-21    ZURN.S  467.319907      -0.004237\n",
       "2023-12-22    ZURN.S  467.883798       0.001207\n",
       "2023-12-27    ZURN.S  468.655209       0.001649\n",
       "2023-12-28    ZURN.S  466.683790      -0.004207\n",
       "2023-12-29    ZURN.S  473.362743       0.014312\n",
       "\n",
       "[3166148 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_RIC         object\n",
      "price            float64\n",
      "Daily_Returns    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = df_raw[[\"stock_RIC\", \"date\", \"price\"]].copy(deep=True)\n",
    "\n",
    "# Convert 'date' column to datetime, coercing errors to NaT\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaT in 'date' column\n",
    "df.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "# Drop rows with NaN in 'price' column and make sure the change is in-place\n",
    "df.dropna(subset=[\"price\"], inplace=True)\n",
    "\n",
    "######## getting rid of time\n",
    "df['date'] = df['date'].dt.date\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "#######\n",
    "\n",
    "df.to_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/stock_level_data/cleaned_stock_level_data.csv\", index=False)\n",
    "\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "######################## Calculate daily returns for each stock\n",
    "df['Daily_Returns'] = df.groupby('stock_RIC')['price'].pct_change()\n",
    "df.dropna(subset=[\"Daily_Returns\"], inplace = True)\n",
    "\n",
    "display(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance ratio - working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stock_RIC       date  Variance_Ratio  Count_Returns\n",
      "0  0MW4EUR.xbo^K15 2014-09-30        0.938783            7.0\n",
      "1  0MW4EUR.xbo^K15 2014-12-31        1.138249           13.0\n",
      "2  0MW4EUR.xbo^K15 2015-03-31        1.363008           13.0\n",
      "3  0MW4EUR.xbo^K15 2015-06-30        0.956091           13.0\n",
      "4  0MW4EUR.xbo^K15 2015-09-30        1.082309           14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "######################## working\n",
    "\n",
    "def calculate_variance_ratio(data):\n",
    "    # Calculate five-day returns by summing log returns over five days\n",
    "    data['Five_Day_Returns'] = np.log(1 + data['Daily_Returns']).rolling(window=5, min_periods=5).sum()\n",
    "\n",
    "    # Identify every 5th trading day, considering actual data days for non-overlapping periods\n",
    "    mask = data.index.to_series().groupby(data['stock_RIC']).cumcount() % 5 == 0\n",
    "\n",
    "    # Calculate the variance of the five-day returns for these non-overlapping periods\n",
    "    five_day_var = data.loc[mask, 'Five_Day_Returns'].var(ddof=1)\n",
    "\n",
    "    # how many times we perform a variance calculation\n",
    "    num_periods = mask.sum()\n",
    "\n",
    "    # Calculate the daily variance (average of variances over the 5-day windows)\n",
    "    daily_var = data['Daily_Returns'].rolling(window=5, min_periods=5).var(ddof=1).loc[mask].mean()\n",
    "\n",
    "    # # Count the number of actual data points in each 5-day window used for the variance calculation\n",
    "    # count_returns = data['Daily_Returns'].rolling(window=5, min_periods=5).count().loc[mask]\n",
    "\n",
    "    # Calculate the variance ratio\n",
    "    variance_ratio = five_day_var / (5 * daily_var) if daily_var > 0 else np.nan\n",
    "    \n",
    "    # Return both the variance ratio and the count of returns in the last used window\n",
    "    return pd.Series({'Variance_Ratio': variance_ratio, 'Count_Returns': num_periods})\n",
    "\n",
    "# Apply the function within each stock group and possibly resample by quarter\n",
    "variance_ratios = df.groupby('stock_RIC').apply(lambda x: x.resample('Q').apply(calculate_variance_ratio))\n",
    "\n",
    "# Reset index if needed and clean up the DataFrame\n",
    "variance_ratios.reset_index(inplace=True)\n",
    "# variance_ratios.drop(columns=['level_2'], inplace=True)  # Drop extra index level if present\n",
    "\n",
    "\n",
    "# Display or save results\n",
    "print(variance_ratios.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>date</th>\n",
       "      <th>Variance_Ratio</th>\n",
       "      <th>Count_Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>0.938783</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.138249</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>1.363008</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>0.956091</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>1.082309</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48288</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0.541870</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48289</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>0.363773</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48290</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>0.091620</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48291</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>1.560581</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48292</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.993398</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48293 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             stock_RIC       date  Variance_Ratio  Count_Returns\n",
       "0      0MW4EUR.xbo^K15 2014-09-30        0.938783            7.0\n",
       "1      0MW4EUR.xbo^K15 2014-12-31        1.138249           13.0\n",
       "2      0MW4EUR.xbo^K15 2015-03-31        1.363008           13.0\n",
       "3      0MW4EUR.xbo^K15 2015-06-30        0.956091           13.0\n",
       "4      0MW4EUR.xbo^K15 2015-09-30        1.082309           14.0\n",
       "...                ...        ...             ...            ...\n",
       "48288           ZURN.S 2022-12-31        0.541870           13.0\n",
       "48289           ZURN.S 2023-03-31        0.363773           13.0\n",
       "48290           ZURN.S 2023-06-30        0.091620           12.0\n",
       "48291           ZURN.S 2023-09-30        1.560581           13.0\n",
       "48292           ZURN.S 2023-12-31        0.993398           13.0\n",
       "\n",
       "[48293 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(variance_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>Variance_Ratio</th>\n",
       "      <th>Five_Day_Variance</th>\n",
       "      <th>Daily_Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>[0.9899525941564677, 1.2399895240146113, 1.211...</td>\n",
       "      <td>date\n",
       "2014-09-30    8.111848e-04\n",
       "2014-12-31    ...</td>\n",
       "      <td>date\n",
       "2014-09-30    1.638836e-04\n",
       "2014-12-31    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1COV.DE</td>\n",
       "      <td>[1.4636806377192533, 1.285175215297745, 1.0939...</td>\n",
       "      <td>date\n",
       "2015-12-31    0.002388\n",
       "2016-03-31    0.00...</td>\n",
       "      <td>date\n",
       "2015-12-31    0.000326\n",
       "2016-03-31    0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>[1.593144661506048, 0.24033873807699696, 0.660...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.004594\n",
       "2010-06-30    0.00...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.000577\n",
       "2010-06-30    0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2.MI</td>\n",
       "      <td>[2.135346142397572, 1.297300927999113, 1.40868...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.001497\n",
       "2010-06-30    0.00...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.000140\n",
       "2010-06-30    0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAA.L^C21</td>\n",
       "      <td>[nan, 1.1809050724638672, 1.3162101482025728, ...</td>\n",
       "      <td>date\n",
       "2014-06-30         NaN\n",
       "2014-09-30    0.00...</td>\n",
       "      <td>date\n",
       "2014-06-30    0.000266\n",
       "2014-09-30    0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>ZO1G.DE^A22</td>\n",
       "      <td>[0.7600914437290106, 0.5645998725626117, 0.453...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.001415\n",
       "2010-06-30    0.00...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.000372\n",
       "2010-06-30    0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>ZODC.PA^C18</td>\n",
       "      <td>[0.652244736652197, 0.8315686613307806, 0.7972...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.001054\n",
       "2010-06-30    0.00...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.000323\n",
       "2010-06-30    0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>ZODCEUR.xbo^C18</td>\n",
       "      <td>[1.8288379933542076, 1.384096373619694, 1.2675...</td>\n",
       "      <td>date\n",
       "2014-09-30    0.000846\n",
       "2014-12-31    0.00...</td>\n",
       "      <td>date\n",
       "2014-09-30    0.000092\n",
       "2014-12-31    0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>ZOTssEUR.xbo^E22</td>\n",
       "      <td>[1.6032775254656204, 1.2124476545521203, 0.782...</td>\n",
       "      <td>date\n",
       "2014-09-30    9.244114e-04\n",
       "2014-12-31    ...</td>\n",
       "      <td>date\n",
       "2014-09-30    1.153152e-04\n",
       "2014-12-31    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>[0.49351549456627425, 1.0925453992062364, 1.54...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.000283\n",
       "2010-06-30    0.00...</td>\n",
       "      <td>date\n",
       "2010-03-31    0.000115\n",
       "2010-06-30    0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             stock_RIC                                     Variance_Ratio  \\\n",
       "0      0MW4EUR.xbo^K15  [0.9899525941564677, 1.2399895240146113, 1.211...   \n",
       "1              1COV.DE  [1.4636806377192533, 1.285175215297745, 1.0939...   \n",
       "2               1U1.DE  [1.593144661506048, 0.24033873807699696, 0.660...   \n",
       "3                A2.MI  [2.135346142397572, 1.297300927999113, 1.40868...   \n",
       "4           AAAA.L^C21  [nan, 1.1809050724638672, 1.3162101482025728, ...   \n",
       "...                ...                                                ...   \n",
       "1008       ZO1G.DE^A22  [0.7600914437290106, 0.5645998725626117, 0.453...   \n",
       "1009       ZODC.PA^C18  [0.652244736652197, 0.8315686613307806, 0.7972...   \n",
       "1010   ZODCEUR.xbo^C18  [1.8288379933542076, 1.384096373619694, 1.2675...   \n",
       "1011  ZOTssEUR.xbo^E22  [1.6032775254656204, 1.2124476545521203, 0.782...   \n",
       "1012            ZURN.S  [0.49351549456627425, 1.0925453992062364, 1.54...   \n",
       "\n",
       "                                      Five_Day_Variance  \\\n",
       "0     date\n",
       "2014-09-30    8.111848e-04\n",
       "2014-12-31    ...   \n",
       "1     date\n",
       "2015-12-31    0.002388\n",
       "2016-03-31    0.00...   \n",
       "2     date\n",
       "2010-03-31    0.004594\n",
       "2010-06-30    0.00...   \n",
       "3     date\n",
       "2010-03-31    0.001497\n",
       "2010-06-30    0.00...   \n",
       "4     date\n",
       "2014-06-30         NaN\n",
       "2014-09-30    0.00...   \n",
       "...                                                 ...   \n",
       "1008  date\n",
       "2010-03-31    0.001415\n",
       "2010-06-30    0.00...   \n",
       "1009  date\n",
       "2010-03-31    0.001054\n",
       "2010-06-30    0.00...   \n",
       "1010  date\n",
       "2014-09-30    0.000846\n",
       "2014-12-31    0.00...   \n",
       "1011  date\n",
       "2014-09-30    9.244114e-04\n",
       "2014-12-31    ...   \n",
       "1012  date\n",
       "2010-03-31    0.000283\n",
       "2010-06-30    0.00...   \n",
       "\n",
       "                                         Daily_Variance  \n",
       "0     date\n",
       "2014-09-30    1.638836e-04\n",
       "2014-12-31    ...  \n",
       "1     date\n",
       "2015-12-31    0.000326\n",
       "2016-03-31    0.00...  \n",
       "2     date\n",
       "2010-03-31    0.000577\n",
       "2010-06-30    0.00...  \n",
       "3     date\n",
       "2010-03-31    0.000140\n",
       "2010-06-30    0.00...  \n",
       "4     date\n",
       "2014-06-30    0.000266\n",
       "2014-09-30    0.00...  \n",
       "...                                                 ...  \n",
       "1008  date\n",
       "2010-03-31    0.000372\n",
       "2010-06-30    0.00...  \n",
       "1009  date\n",
       "2010-03-31    0.000323\n",
       "2010-06-30    0.00...  \n",
       "1010  date\n",
       "2014-09-30    0.000092\n",
       "2014-12-31    0.00...  \n",
       "1011  date\n",
       "2014-09-30    1.153152e-04\n",
       "2014-12-31    ...  \n",
       "1012  date\n",
       "2010-03-31    0.000115\n",
       "2010-06-30    0.00...  \n",
       "\n",
       "[1013 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(variance_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stock_RIC                                     Variance_Ratio  \\\n",
      "0  0MW4EUR.xbo^K15  [0.9899525941564677, 1.2399895240146113, 1.211...   \n",
      "1          1COV.DE  [1.4636806377192533, 1.285175215297745, 1.0939...   \n",
      "2           1U1.DE  [1.593144661506048, 0.24033873807699696, 0.660...   \n",
      "3            A2.MI  [2.135346142397572, 1.297300927999113, 1.40868...   \n",
      "4       AAAA.L^C21  [nan, 1.1809050724638672, 1.3162101482025728, ...   \n",
      "\n",
      "                                   Five_Day_Variance  \\\n",
      "0  date\n",
      "2014-09-30    8.111848e-04\n",
      "2014-12-31    ...   \n",
      "1  date\n",
      "2015-12-31    0.002388\n",
      "2016-03-31    0.00...   \n",
      "2  date\n",
      "2010-03-31    0.004594\n",
      "2010-06-30    0.00...   \n",
      "3  date\n",
      "2010-03-31    0.001497\n",
      "2010-06-30    0.00...   \n",
      "4  date\n",
      "2014-06-30         NaN\n",
      "2014-09-30    0.00...   \n",
      "\n",
      "                                      Daily_Variance  \n",
      "0  date\n",
      "2014-09-30    1.638836e-04\n",
      "2014-12-31    ...  \n",
      "1  date\n",
      "2015-12-31    0.000326\n",
      "2016-03-31    0.00...  \n",
      "2  date\n",
      "2010-03-31    0.000577\n",
      "2010-06-30    0.00...  \n",
      "3  date\n",
      "2010-03-31    0.000140\n",
      "2010-06-30    0.00...  \n",
      "4  date\n",
      "2014-06-30    0.000266\n",
      "2014-09-30    0.00...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_quarterly_variance_ratio(data):\n",
    "    # Ensure daily returns are calculated if not present\n",
    "    if 'Daily_Returns' not in data.columns:\n",
    "        data['Daily_Returns'] = data['price'].pct_change()\n",
    "\n",
    "    # Calculate five-day returns by summing log returns over five days\n",
    "    data['Five_Day_Returns'] = np.log(1 + data['Daily_Returns']).rolling(window=5, min_periods=5).sum()\n",
    "\n",
    "    # Identify non-overlapping 5th days\n",
    "    mask = data.index.to_series().groupby(data['stock_RIC']).cumcount() % 5 == 0\n",
    "    non_overlapping_five_day_returns = data.loc[mask, 'Five_Day_Returns']\n",
    "\n",
    "    # Calculate the variance of these non-overlapping five-day returns for each quarter\n",
    "    five_day_var = non_overlapping_five_day_returns.resample('Q').var(ddof=1)\n",
    "\n",
    "    # Calculate the variance of all daily returns for each quarter\n",
    "    daily_var = data['Daily_Returns'].resample('Q').var(ddof=1)\n",
    "\n",
    "    # Calculate the variance ratio\n",
    "    # This needs to handle Series, so use numpy where for vectorized conditional operation\n",
    "    variance_ratio = np.where(daily_var > 0, five_day_var / (5 * daily_var), np.nan)\n",
    "\n",
    "    # Return results as a Series\n",
    "    return pd.Series({\n",
    "        'Variance_Ratio': variance_ratio,\n",
    "        'Five_Day_Variance': five_day_var,\n",
    "        'Daily_Variance': daily_var\n",
    "    })\n",
    "\n",
    "# Assuming df is prepared\n",
    "variance_ratios = df.groupby('stock_RIC').apply(calculate_quarterly_variance_ratio)\n",
    "\n",
    "# Reset index and cleanup\n",
    "variance_ratios.reset_index(inplace=True)\n",
    "if 'level_2' in variance_ratios.columns:\n",
    "    variance_ratios.drop(columns=['level_2'], inplace=True)\n",
    "\n",
    "print(variance_ratios.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date stock_RIC Variance_Ratio Count_Returns\n",
      "0 2010-03-31    1U1.DE        1.79202          13.0\n",
      "1 2010-03-31     A2.MI       2.733786          13.0\n",
      "2 2010-03-31    AAK.ST       1.365109          13.0\n",
      "3 2010-03-31     AAL.L       1.017296          13.0\n",
      "4 2010-03-31   AALB.AS       1.146916          13.0\n"
     ]
    }
   ],
   "source": [
    "# Create a date range for quarters between 2010 and 2023\n",
    "quarter_dates = pd.date_range(start='2010-01-01', end='2023-12-31', freq='Q')\n",
    "\n",
    "# Assuming you have a list of all unique stock_RICs from your original DataFrame\n",
    "stocks = df['stock_RIC'].unique()\n",
    "\n",
    "# Create a DataFrame from all combinations of quarter_dates and stocks\n",
    "quarters = pd.MultiIndex.from_product([quarter_dates, stocks], names=['date', 'stock_RIC'])\n",
    "df_quarters = pd.DataFrame(index=quarters).reset_index()\n",
    "\n",
    "# Format the 'date' to datetime if not already\n",
    "df_quarters['date'] = pd.to_datetime(df_quarters['date'])\n",
    "\n",
    "\n",
    "# Merge the complete quarters DataFrame with the variance_ratios\n",
    "final_df = df_quarters.merge(variance_ratios, on=['date', 'stock_RIC'], how='left')\n",
    "\n",
    "# Fill NA for quarters with no data\n",
    "final_df.fillna('NA', inplace=True)\n",
    "\n",
    "# Check the final DataFrame\n",
    "print(final_df.head())\n",
    "\n",
    "# Optionally, you might want to sort or reindex based on your needs\n",
    "final_df.sort_values(by=['stock_RIC', 'date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/variable_data/variance_ratio.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create quaterly data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>date_quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>2010-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>2010-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>2010-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>2010-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1U1.DE</td>\n",
       "      <td>2011-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55710</th>\n",
       "      <td>SYENS.BR</td>\n",
       "      <td>2022-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55711</th>\n",
       "      <td>SYENS.BR</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55712</th>\n",
       "      <td>SYENS.BR</td>\n",
       "      <td>2023-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55713</th>\n",
       "      <td>SYENS.BR</td>\n",
       "      <td>2023-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55714</th>\n",
       "      <td>SYENS.BR</td>\n",
       "      <td>2023-09-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stock_RIC date_quarter\n",
       "0        1U1.DE   2010-03-31\n",
       "1        1U1.DE   2010-06-30\n",
       "2        1U1.DE   2010-09-30\n",
       "3        1U1.DE   2010-12-31\n",
       "4        1U1.DE   2011-03-31\n",
       "...         ...          ...\n",
       "55710  SYENS.BR   2022-09-30\n",
       "55711  SYENS.BR   2022-12-31\n",
       "55712  SYENS.BR   2023-03-31\n",
       "55713  SYENS.BR   2023-06-30\n",
       "55714  SYENS.BR   2023-09-30\n",
       "\n",
       "[55715 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a date range of quarters\n",
    "quarters = pd.date_range(start='2010-01-01', end='2023-12-01', freq='Q')\n",
    "\n",
    "# Get unique stock identifiers from your dataset\n",
    "stocks = df['stock_RIC'].unique()\n",
    "\n",
    "# Create a DataFrame from every combination of stock_RIC and date\n",
    "df_q = pd.MultiIndex.from_product([stocks, quarters], names=['stock_RIC', 'date_quarter']).to_frame(index=False)\n",
    "\n",
    "display(df_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate variance for each quarter\n",
    "\n",
    "#### GPT prompt v1\n",
    "The data frame df contains return data. please calculate for each row the variance from the daily returns that are within the quarter. for 2010-03-31 is should consider all returns from 2010-01-01 till 2010-03-31. if there are no returns to calculate the variance put in a NA. the new column should be called daily_variance.\n",
    "\n",
    "Create a second column called 5_day_variance. Identify every 5th trading day, considering actual data days for non-overlapping periods. here you first need to calculate the five_day_returns. for all five_day_returns within a quarter you should again calculate the variance: five_day_variance. count the number of five_day_returns for each quarter and put them in a new column named count. if there are no returns fill in NA for the variance and also for count\n",
    "\n",
    "add the new columns to the df_q. df_q is a data frame with rows for each quarter between 2010-01-01 and 2023-12-31 for each stock_RIC\n",
    "\n",
    "#### GPT promt v2\n",
    "can you extract all data points for each quarter from an existing df. the new data frame df_q has a row for each stock_RIC for each quarter between 2010-01-01 to 2023-31-12. for each date_quarter go to the data set df and get all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:557\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 557\u001b[0m     parsed, reso \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_with_reso(key)\n\u001b[1;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, pytz\u001b[39m.\u001b[39mNonExistentTimeError) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:513\u001b[0m, in \u001b[0;36mDatetimeIndex._parse_with_reso\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_parse_with_reso\u001b[39m(\u001b[39mself\u001b[39m, label: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     parsed, reso \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_parse_with_reso(label)\n\u001b[1;32m    515\u001b[0m     parsed \u001b[39m=\u001b[39m Timestamp(parsed)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/datetimelike.py:267\u001b[0m, in \u001b[0;36mDatetimeIndexOpsMixin._parse_with_reso\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    265\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(label)\n\u001b[0;32m--> 267\u001b[0m parsed, reso_str \u001b[39m=\u001b[39m parsing\u001b[39m.\u001b[39mparse_datetime_string_with_reso(label, freqstr)\n\u001b[1;32m    268\u001b[0m reso \u001b[39m=\u001b[39m Resolution\u001b[39m.\u001b[39mfrom_attrname(reso_str)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/parsing.pyx:435\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string_with_reso\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/parsing.pyx:658\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: Daily_Returns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:269\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_agg_general(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[39m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[39m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[39m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:288\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_with_exclusions\n\u001b[0;32m--> 288\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39magg_series(obj, f)\n\u001b[1;32m    289\u001b[0m res \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_constructor(result, name\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mname)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    992\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    996\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[0;32m-> 1015\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[1;32m   1016\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:285\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    284\u001b[0m func \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mis_builtin_func(func)\n\u001b[0;32m--> 285\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    287\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_with_exclusions\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:428\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(how):\n\u001b[1;32m    426\u001b[0m     \u001b[39m# TODO: test_resample_apply_with_additional_args fails if we go\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[39m#  through the non-lambda path, not clear that it should.\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: how(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    429\u001b[0m     result \u001b[39m=\u001b[39m grouped\u001b[39m.\u001b[39maggregate(func)\n",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb Cell 15\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_5_day_stats\u001b[39m(group):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Calculate 5-day returns\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     group[\u001b[39m'\u001b[39m\u001b[39mFive_Day_Returns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mDaily_Returns\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mrolling(window\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_periods\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Correctly apply cumcount() within a groupby context\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:559\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, pytz\u001b[39m.\u001b[39mNonExistentTimeError) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 559\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disallow_mismatched_indexing(parsed)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Daily_Returns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:557\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 557\u001b[0m     parsed, reso \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_with_reso(key)\n\u001b[1;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, pytz\u001b[39m.\u001b[39mNonExistentTimeError) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:513\u001b[0m, in \u001b[0;36mDatetimeIndex._parse_with_reso\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_parse_with_reso\u001b[39m(\u001b[39mself\u001b[39m, label: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     parsed, reso \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_parse_with_reso(label)\n\u001b[1;32m    515\u001b[0m     parsed \u001b[39m=\u001b[39m Timestamp(parsed)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/datetimelike.py:267\u001b[0m, in \u001b[0;36mDatetimeIndexOpsMixin._parse_with_reso\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    265\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(label)\n\u001b[0;32m--> 267\u001b[0m parsed, reso_str \u001b[39m=\u001b[39m parsing\u001b[39m.\u001b[39mparse_datetime_string_with_reso(label, freqstr)\n\u001b[1;32m    268\u001b[0m reso \u001b[39m=\u001b[39m Resolution\u001b[39m.\u001b[39mfrom_attrname(reso_str)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/parsing.pyx:435\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string_with_reso\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/parsing.pyx:658\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: Daily_Returns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:429\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate\u001b[0;34m(self, how, *args, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: how(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 429\u001b[0m     result \u001b[39m=\u001b[39m grouped\u001b[39m.\u001b[39maggregate(func)\n\u001b[1;32m    430\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1304\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1304\u001b[0m     result \u001b[39m=\u001b[39m gba\u001b[39m.\u001b[39magg()\n\u001b[1;32m   1306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:166\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    165\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(arg):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:355\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m     new_res \u001b[39m=\u001b[39m colg\u001b[39m.\u001b[39maggregate(arg, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[1;32m    356\u001b[0m results\u001b[39m.\u001b[39mappend(new_res)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:238\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m--> 238\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m relabeling:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:316\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m         key \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mOutputKey(label\u001b[39m=\u001b[39mname, position\u001b[39m=\u001b[39midx)\n\u001b[0;32m--> 316\u001b[0m         results[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, DataFrame) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:274\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[39m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[39m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[39m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_named(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    276\u001b[0m     \u001b[39m# result is a dict whose keys are the elements of result_index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:412\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_named\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(group, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m, name)\n\u001b[0;32m--> 412\u001b[0m output \u001b[39m=\u001b[39m func(group, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    413\u001b[0m output \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(output)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:428\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(how):\n\u001b[1;32m    426\u001b[0m     \u001b[39m# TODO: test_resample_apply_with_additional_args fails if we go\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[39m#  through the non-lambda path, not clear that it should.\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: how(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    429\u001b[0m     result \u001b[39m=\u001b[39m grouped\u001b[39m.\u001b[39maggregate(func)\n",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb Cell 15\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_5_day_stats\u001b[39m(group):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Calculate 5-day returns\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     group[\u001b[39m'\u001b[39m\u001b[39mFive_Day_Returns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mDaily_Returns\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mrolling(window\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_periods\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Correctly apply cumcount() within a groupby context\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:559\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, pytz\u001b[39m.\u001b[39mNonExistentTimeError) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 559\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disallow_mismatched_indexing(parsed)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Daily_Returns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m daily_variance \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mstock_RIC\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mresample(\u001b[39m'\u001b[39m\u001b[39mQ\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mDaily_Returns\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvar()\u001b[39m.\u001b[39mrename(\u001b[39m'\u001b[39m\u001b[39mdaily_variance\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Calculate 5-day variance and count for each quarter\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m five_day_stats \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mstock_RIC\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mresample(\u001b[39m'\u001b[39m\u001b[39mQ\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mapply(calculate_5_day_stats)\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:332\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     how \u001b[39m=\u001b[39m func\n\u001b[0;32m--> 332\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_groupby_and_aggregate(how, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    334\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:1196\u001b[0m, in \u001b[0;36m_GroupByMixin._apply\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(x, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1194\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1196\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_groupby\u001b[39m.\u001b[39mapply(func)\n\u001b[1;32m   1197\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_result(result)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1352\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_apply_general(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selected_obj)\n\u001b[1;32m   1354\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_apply_general(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39mapply(f, data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis)\n\u001b[1;32m   1403\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:1194\u001b[0m, in \u001b[0;36m_GroupByMixin._apply.<locals>.func\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(x, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1194\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:332\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     how \u001b[39m=\u001b[39m func\n\u001b[0;32m--> 332\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_groupby_and_aggregate(how, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    334\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:440\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate\u001b[0;34m(self, how, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         result \u001b[39m=\u001b[39m grouped\u001b[39m.\u001b[39maggregate(how, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m):\n\u001b[1;32m    433\u001b[0m     \u001b[39m# we have a non-reducing function; try to evaluate\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39m# alternatively we want to evaluate only a column of the input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[39m#  on Series, raising AttributeError or KeyError\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39m#  (depending on whether the column lookup uses getattr/__getitem__)\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     result \u001b[39m=\u001b[39m grouped\u001b[39m.\u001b[39mapply(how, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    443\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMust produce aggregated value\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n\u001b[1;32m    444\u001b[0m         \u001b[39m# raised in _aggregate_named\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         \u001b[39m# see test_apply_without_aggregation, test_apply_with_mutated_index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1352\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_apply_general(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selected_obj)\n\u001b[1;32m   1354\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_apply_general(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39mapply(f, data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis)\n\u001b[1;32m   1403\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m mask \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mstock_RIC\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcumcount() \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Reset index if the date is the index\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Select non-overlapping five-day returns\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m five_day_returns \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39mloc[mask, \u001b[39m'\u001b[39m\u001b[39mFive_Day_Returns\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Calculate variance of five-day returns\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/variable_construction/dependent_variable.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m five_day_variance \u001b[39m=\u001b[39m five_day_returns\u001b[39m.\u001b[39mvar()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1289\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:955\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    953\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 955\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(retval, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\u001b[39m.\u001b[39m_getitem_axis(key, axis\u001b[39m=\u001b[39mi)\n\u001b[1;32m    956\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1325\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_slice_axis(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   1324\u001b[0m \u001b[39melif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getbool_axis(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   1326\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m   1327\u001b[0m     \u001b[39m# an iterable multi-selection\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1121\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getbool_axis\u001b[39m(\u001b[39mself\u001b[39m, key, axis: AxisInt):\n\u001b[1;32m   1119\u001b[0m     \u001b[39m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m-> 1121\u001b[0m     key \u001b[39m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[1;32m   1122\u001b[0m     inds \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(inds, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:2506\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2504\u001b[0m indexer \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_indexer_for(index)\n\u001b[1;32m   2505\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39min\u001b[39;00m indexer:\n\u001b[0;32m-> 2506\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\n\u001b[1;32m   2507\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnalignable boolean Series provided as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2508\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mindexer (index of the boolean Series and of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2509\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe indexed object do not match).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2510\u001b[0m     )\n\u001b[1;32m   2512\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   2514\u001b[0m \u001b[39m# fall through for boolean\u001b[39;00m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate daily variance for each quarter\n",
    "daily_variance = df.groupby('stock_RIC').resample('Q')['Daily_Returns'].var().rename('daily_variance').reset_index()\n",
    "\n",
    "def calculate_5_day_stats(group):\n",
    "    # Calculate 5-day returns\n",
    "    group['Five_Day_Returns'] = np.log(1 + group['Daily_Returns']).rolling(window=5, min_periods=5).sum()\n",
    "    \n",
    "    # Correctly apply cumcount() within a groupby context\n",
    "    mask = group.reset_index().groupby('stock_RIC').cumcount() % 5 == 0  # Reset index if the date is the index\n",
    "    \n",
    "    # Select non-overlapping five-day returns\n",
    "    five_day_returns = group.loc[mask, 'Five_Day_Returns']\n",
    "    \n",
    "    # Calculate variance of five-day returns\n",
    "    five_day_variance = five_day_returns.var()\n",
    "    \n",
    "    # Count valid non-overlapping 5-day periods\n",
    "    count = five_day_returns.count()\n",
    "    \n",
    "    return pd.Series({\n",
    "        'five_day_variance': five_day_variance if count > 0 else np.nan,\n",
    "        'count': count\n",
    "    })\n",
    "\n",
    "# Calculate daily variance for each quarter\n",
    "daily_variance = df.groupby('stock_RIC').resample('Q')['Daily_Returns'].var().rename('daily_variance').reset_index()\n",
    "\n",
    "# Calculate 5-day variance and count for each quarter\n",
    "five_day_stats = df.groupby('stock_RIC').resample('Q').apply(calculate_5_day_stats).reset_index()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
