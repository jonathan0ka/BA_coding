{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2010_01_2013_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2014_01_2015_11.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2020_01_2020_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2021_01_2022_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2019_01_2019_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2023_01_2023_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2016_12_2018_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2014_07_2016_11.csv\n",
      "All CSV files have been merged into /Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def merge_csv_files(directory_path, output_file):\n",
    "    # List to hold data from each CSV file\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Read the CSV file and append to the list\n",
    "            print(file_path)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatenate all dataframes in the list\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Write the merged dataframe to a new CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"All CSV files have been merged into {output_file}\")\n",
    "\n",
    "# Usage\n",
    "directory_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data'  # Update this path to the directory containing your CSV files\n",
    "output_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv'  # Update this path to where you want the merged CSV to be saved\n",
    "merge_csv_files(directory_path, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETF ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (16351213) does not match length of index (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m input_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Update this path to your actual CSV file path\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m output_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/etf_merged_holdings.csv\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Update this path to where you want the filtered data saved\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m filter_and_export_csv_dask(input_file, output_file)\n",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m filtered_ddf \u001b[39m=\u001b[39m ddf[(ddf[\u001b[39m'\u001b[39m\u001b[39mfund_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mExchange-Traded Fund\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m|\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                    ddf[\u001b[39m'\u001b[39m\u001b[39mfund_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m'\u001b[39m\u001b[39mVanguard\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# adjust date\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m filtered_ddf[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(filtered_ddf[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Subtract one month end to change the date to the last day of the previous month\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m filtered_ddf[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m filtered_ddf[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m pd\u001b[39m.\u001b[39moffsets\u001b[39m.\u001b[39mMonthEnd(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/dask/dataframe/core.py:4922\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4920\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mItem assignment with \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(key)\u001b[39m}\u001b[39;00m\u001b[39m not supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4922\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massign(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{key: value})\n\u001b[1;32m   4924\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdask \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdask\n\u001b[1;32m   4925\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_name\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/dask/dataframe/core.py:5369\u001b[0m, in \u001b[0;36mDataFrame.assign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   5366\u001b[0m     pairs \u001b[39m=\u001b[39m [k, kwargs[k]]\n\u001b[1;32m   5368\u001b[0m     \u001b[39m# Figure out columns of the output\u001b[39;00m\n\u001b[0;32m-> 5369\u001b[0m     df2 \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39m_meta_nonempty\u001b[39m.\u001b[39massign(\n\u001b[1;32m   5370\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_extract_meta({k: kwargs[k]}, nonempty\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   5371\u001b[0m     )\n\u001b[1;32m   5372\u001b[0m     data \u001b[39m=\u001b[39m elemwise(methods\u001b[39m.\u001b[39massign, data, \u001b[39m*\u001b[39mpairs, meta\u001b[39m=\u001b[39mdf2)\n\u001b[1;32m   5374\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4844\u001b[0m, in \u001b[0;36mDataFrame.assign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4841\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   4843\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems():\n\u001b[0;32m-> 4844\u001b[0m     data[k] \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(v, data)\n\u001b[1;32m   4845\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (16351213) does not match length of index (2)"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_export_csv_dask(input_file, output_file):\n",
    "    # Read the file using Dask\n",
    "    ddf = dd.read_csv(input_file)\n",
    "\n",
    "    # Drop rows with NaN in 'fund_type' or 'fund_name'\n",
    "    ddf = ddf.dropna(subset=['fund_type', 'fund_name'])\n",
    "    \n",
    "    # Apply filtering conditions\n",
    "    filtered_ddf = ddf[(ddf['fund_type'] == 'Exchange-Traded Fund') |\n",
    "                       ddf['fund_name'].str.contains('Vanguard')]\n",
    "\n",
    "\n",
    "    # Compute and write the result to a new CSV file\n",
    "    filtered_ddf.compute().to_csv(output_file, index=False)\n",
    "    print(f\"Filtered data has been saved to {output_file}\")\n",
    "\n",
    "# Usage\n",
    "input_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv'  # Update this path to your actual CSV file path\n",
    "output_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/etf_merged_holdings.csv'  # Update this path to where you want the filtered data saved\n",
    "filter_and_export_csv_dask(input_file, output_file)\n",
    "\n",
    "filtered_ddf = pd.read_csv(output_file)\n",
    "\n",
    "# adjust date\n",
    "filtered_ddf['date'] = pd.to_datetime(filtered_ddf['date'])\n",
    "\n",
    "# Subtract one month end to change the date to the last day of the previous month\n",
    "filtered_ddf['date'] = filtered_ddf['date'] - pd.offsets.MonthEnd(1)\n",
    "\n",
    "filtered_ddf.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum up etf ownership of each stock on a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/etf_merged_holdings.csv\")\n",
    "\n",
    "# Group by 'stock_RIC' and 'date', and sum the 'stock_value_held'\n",
    "grouped_df = df.groupby(['stock_RIC', 'date'])[['stock_value_held', \"percent_of_traded_shares\"]].sum().reset_index()\n",
    "\n",
    "# Export to new CSV\n",
    "file_path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_etf_holdings_600_.csv\"\n",
    "grouped_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fund ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to /Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/fund_ex_merged_holdings.csv\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def filter_and_export_csv_dask(input_file, output_file):\n",
    "    # Read the file using Dask\n",
    "    ddf = dd.read_csv(input_file)\n",
    "\n",
    "    # Drop rows with NaN in 'fund_type' or 'fund_name'\n",
    "    ddf = ddf.dropna(subset=['fund_type', 'fund_name'])\n",
    "    \n",
    "    # Apply filtering conditions\n",
    "    filtered_ddf = ddf[(ddf['fund_type'] != 'Exchange-Traded Fund') |\n",
    "                        ddf['fund_name'].str.contains('Vanguard') == False]\n",
    "    \n",
    "    # Compute and write the result to a new CSV file\n",
    "    filtered_ddf.compute().to_csv(output_file, index=False)\n",
    "    print(f\"Filtered data has been saved to {output_file}\")\n",
    "\n",
    "# Usage\n",
    "input_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv'  # Update this path to your actual CSV file path\n",
    "output_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/fund_ex_merged_holdings.csv'  # Update this path to where you want the filtered data saved\n",
    "filter_and_export_csv_dask(input_file, output_file)\n",
    "\n",
    "output_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/fund_ex_merged_holdings.csv'\n",
    "\n",
    "filtered_ddf = pd.read_csv(output_file)\n",
    "\n",
    "# adjust date\n",
    "filtered_ddf['date'] = pd.to_datetime(filtered_ddf['date'])\n",
    "\n",
    "# Subtract one month end to change the date to the last day of the previous month\n",
    "filtered_ddf['date'] = filtered_ddf['date'] - pd.offsets.MonthEnd(1)\n",
    "\n",
    "filtered_ddf.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum up fund ex etf ownership of each stock on a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/fund_ex_merged_holdings.csv\")\n",
    "\n",
    "# Group by 'stock_RIC' and 'date', and sum the 'stock_value_held'\n",
    "grouped_df = df.groupby(['stock_RIC', 'date'])[['stock_value_held', \"percent_of_traded_shares\"]].sum().reset_index()\n",
    "\n",
    "grouped_df.rename(columns={'stock_value_held': 'FUND_stock_value_held'},  inplace=True)\n",
    "grouped_df.rename(columns={'percent_of_traded_shares': 'FUND_percent_of_traded_shares'}, inplace=True)\n",
    "\n",
    "# Export to new CSV\n",
    "file_path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_fund_ex_holdings_600_.csv\"\n",
    "grouped_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>date</th>\n",
       "      <th>FUND_stock_value_held</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>9.666637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>9.598608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>8.259427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>9.845493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>9.688948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154456</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>3874.537377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154457</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>3834.866671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154458</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3802.279416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154459</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>3973.467134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154460</th>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>4255.712221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154461 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              stock_RIC        date  FUND_stock_value_held\n",
       "0       0MW4EUR.xbo^K15  2010-01-01               9.666637\n",
       "1       0MW4EUR.xbo^K15  2010-02-01               9.598608\n",
       "2       0MW4EUR.xbo^K15  2010-03-01               8.259427\n",
       "3       0MW4EUR.xbo^K15  2010-04-01               9.845493\n",
       "4       0MW4EUR.xbo^K15  2010-05-01               9.688948\n",
       "...                 ...         ...                    ...\n",
       "154456           ZURN.S  2023-08-01            3874.537377\n",
       "154457           ZURN.S  2023-09-01            3834.866671\n",
       "154458           ZURN.S  2023-10-01            3802.279416\n",
       "154459           ZURN.S  2023-11-01            3973.467134\n",
       "154460           ZURN.S  2023-12-01            4255.712221\n",
       "\n",
       "[154461 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge etf and fund ownership with index membership: formatted_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m file_fund_ownership \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_fund_ex_holdings_600_.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m m_stock_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/stock_level_data/m_stock_level_data.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m merge_csv_files(formatted_index_member, file_etf_ownership, output_file, [\u001b[39m'\u001b[39m\u001b[39mstock_value_held\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpercent_of_traded_shares\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m merge_csv_files(output_file, file_fund_ownership, output_file, [\u001b[39m\"\u001b[39m\u001b[39mFUND_stock_value_held\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFUND_percent_of_traded_shares\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m merge_csv_files(output_file, m_stock_path, output_file, \u001b[39m'\u001b[39m\u001b[39mmarket_cap\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df1[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df1[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df2[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df2[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df2 \u001b[39m=\u001b[39m df2[[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstock_RIC\u001b[39m\u001b[39m\"\u001b[39m, column_added]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m merged_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(df1, df2, on\u001b[39m=\u001b[39mkey_columns, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/etf_holdings/merge_fund_ownership.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Fill NA values in 'stock_value_held' with the desired placeholder if no match was found\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5872\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5869\u001b[0m     keyarr \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39masarray_tuplesafe(keyarr)\n\u001b[1;32m   5871\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 5872\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_for(keyarr)\n\u001b[1;32m   5873\u001b[0m     keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(keyarr)[\u001b[39m0\u001b[39m]\n\u001b[1;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5859\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   5841\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5842\u001b[0m \u001b[39mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[1;32m   5843\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5856\u001b[0m \u001b[39marray([0, 2])\u001b[39;00m\n\u001b[1;32m   5857\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5858\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 5859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer(target)\n\u001b[1;32m   5860\u001b[0m indexer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_non_unique(target)\n\u001b[1;32m   5861\u001b[0m \u001b[39mreturn\u001b[39;00m indexer\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3797\u001b[0m     target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3798\u001b[0m     \u001b[39mreturn\u001b[39;00m this\u001b[39m.\u001b[39m_get_indexer(\n\u001b[1;32m   3799\u001b[0m         target, method\u001b[39m=\u001b[39mmethod, limit\u001b[39m=\u001b[39mlimit, tolerance\u001b[39m=\u001b[39mtolerance\n\u001b[1;32m   3800\u001b[0m     )\n\u001b[0;32m-> 3802\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_indexer(target, method, limit, tolerance)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3829\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3826\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3827\u001b[0m         tgt_values \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39m_get_engine_target()\n\u001b[0;32m-> 3829\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_indexer(tgt_values)\n\u001b[1;32m   3831\u001b[0m \u001b[39mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:321\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(file1, file2, output_file, column_added):\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    key_columns = ['date', 'stock_RIC']\n",
    "\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df2['date'] = pd.to_datetime(df2['date'])\n",
    "\n",
    "    cols_to_keep = key_columns + column_added\n",
    "    df2 = df2[cols_to_keep]\n",
    "\n",
    "    merged_df = pd.merge(df1, df2, on=key_columns, how='left')\n",
    "\n",
    "    # Fill NA values in 'stock_value_held' with the desired placeholder if no match was found\n",
    "    merged_df[column_added].fillna('NA', inplace=True)\n",
    "\n",
    "    # Write the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Merged data has been saved to {output_file}\")\n",
    "\n",
    "\n",
    "formatted_index_member = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/formated_constituents_stoxx_europe_600.csv'\n",
    "output_file = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/formatted_final.csv\"\n",
    "\n",
    "file_etf_ownership = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_etf_holdings_600_.csv'\n",
    "file_fund_ownership = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_fund_ex_holdings_600_.csv\"\n",
    "m_stock_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/stock_level_data/m_stock_level_data.csv'\n",
    "\n",
    "merge_csv_files(formatted_index_member, file_etf_ownership, output_file, ['stock_value_held', \"percent_of_traded_shares\"])\n",
    "merge_csv_files(output_file, file_fund_ownership, output_file, [\"FUND_stock_value_held\", \"FUND_percent_of_traded_shares\"])\n",
    "merge_csv_files(output_file, m_stock_path, output_file, ['market_cap'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETF ownership and Fund owership in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>index_member</th>\n",
       "      <th>stock_value_held</th>\n",
       "      <th>FUND_stock_value_held</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>ETF_ownership</th>\n",
       "      <th>FUND_ownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>0</td>\n",
       "      <td>14.731695</td>\n",
       "      <td>9.666637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>0</td>\n",
       "      <td>11.226477</td>\n",
       "      <td>9.598608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>0</td>\n",
       "      <td>9.887296</td>\n",
       "      <td>8.259427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>0</td>\n",
       "      <td>11.585353</td>\n",
       "      <td>9.845493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>0MW4EUR.xbo^K15</td>\n",
       "      <td>0</td>\n",
       "      <td>15.047999</td>\n",
       "      <td>9.688948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196219</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>5870.052977</td>\n",
       "      <td>3874.537377</td>\n",
       "      <td>6.606391e+10</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>0.058648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196220</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>5816.278767</td>\n",
       "      <td>3834.866671</td>\n",
       "      <td>6.344198e+10</td>\n",
       "      <td>0.091679</td>\n",
       "      <td>0.060447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196221</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>5789.045875</td>\n",
       "      <td>3802.279416</td>\n",
       "      <td>6.357877e+10</td>\n",
       "      <td>0.091053</td>\n",
       "      <td>0.059804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196222</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>6022.326667</td>\n",
       "      <td>3973.467134</td>\n",
       "      <td>6.545329e+10</td>\n",
       "      <td>0.092010</td>\n",
       "      <td>0.060707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196223</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>6366.086468</td>\n",
       "      <td>4255.712221</td>\n",
       "      <td>6.727570e+10</td>\n",
       "      <td>0.094627</td>\n",
       "      <td>0.063258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196224 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date        stock_RIC  index_member  stock_value_held  \\\n",
       "0       2009-12-31  0MW4EUR.xbo^K15             0         14.731695   \n",
       "1       2010-01-31  0MW4EUR.xbo^K15             0         11.226477   \n",
       "2       2010-02-28  0MW4EUR.xbo^K15             0          9.887296   \n",
       "3       2010-03-31  0MW4EUR.xbo^K15             0         11.585353   \n",
       "4       2010-04-30  0MW4EUR.xbo^K15             0         15.047999   \n",
       "...            ...              ...           ...               ...   \n",
       "196219  2023-07-31           ZURN.S             1       5870.052977   \n",
       "196220  2023-08-31           ZURN.S             1       5816.278767   \n",
       "196221  2023-09-30           ZURN.S             1       5789.045875   \n",
       "196222  2023-10-31           ZURN.S             1       6022.326667   \n",
       "196223  2023-11-30           ZURN.S             1       6366.086468   \n",
       "\n",
       "        FUND_stock_value_held    market_cap  ETF_ownership  FUND_ownership  \n",
       "0                    9.666637           NaN            NaN             NaN  \n",
       "1                    9.598608           NaN            NaN             NaN  \n",
       "2                    8.259427           NaN            NaN             NaN  \n",
       "3                    9.845493           NaN            NaN             NaN  \n",
       "4                    9.688948           NaN            NaN             NaN  \n",
       "...                       ...           ...            ...             ...  \n",
       "196219            3874.537377  6.606391e+10       0.088854        0.058648  \n",
       "196220            3834.866671  6.344198e+10       0.091679        0.060447  \n",
       "196221            3802.279416  6.357877e+10       0.091053        0.059804  \n",
       "196222            3973.467134  6.545329e+10       0.092010        0.060707  \n",
       "196223            4255.712221  6.727570e+10       0.094627        0.063258  \n",
       "\n",
       "[196224 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "output_file = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/formatted_final.csv\"\n",
    "df = pd.read_csv(output_file)\n",
    "#############\n",
    "\n",
    "df['ETF_ownership'] = (df[\"stock_value_held\"] * 1_000_000)/ df[\"market_cap\"]\n",
    "df['FUND_ownership'] = (df[\"FUND_stock_value_held\"] * 1_000_000)/ df[\"market_cap\"]\n",
    "type(df)\n",
    "display(df)\n",
    "\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOMALIES: remove duplicates from 2015-03-01 to 2015-11-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2014_01_2015_11.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "## reomve duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.to_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
