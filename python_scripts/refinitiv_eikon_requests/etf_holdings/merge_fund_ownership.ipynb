{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2010_01_2013_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2020_01_2020_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2021_01_2022_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2019_01_2019_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2023_01_2023_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2016_12_2018_12.csv\n",
      "/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data/etf_holdings_600_stocks_2014_07_2016_11.csv\n",
      "All CSV files have been merged into /Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def merge_csv_files(directory_path, output_file):\n",
    "    # List to hold data from each CSV file\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Read the CSV file and append to the list\n",
    "            print(file_path)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatenate all dataframes in the list\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Write the merged dataframe to a new CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"All CSV files have been merged into {output_file}\")\n",
    "\n",
    "# Usage\n",
    "directory_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/raw_data'  # Update this path to the directory containing your CSV files\n",
    "output_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv'  # Update this path to where you want the merged CSV to be saved\n",
    "merge_csv_files(directory_path, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETF ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/dask/dataframe/io/csv.py:195: DtypeWarning: Columns (1,2,3,4,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to /Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/etf_merged_holdings.csv\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def filter_and_export_csv_dask(input_file, output_file):\n",
    "    # Read the file using Dask\n",
    "    ddf = dd.read_csv(input_file)\n",
    "\n",
    "    # Drop rows with NaN in 'fund_type' or 'fund_name'\n",
    "    ddf = ddf.dropna(subset=['fund_type', 'fund_name'])\n",
    "    \n",
    "    # Apply filtering conditions\n",
    "    filtered_ddf = ddf[(ddf['fund_type'] == 'Exchange-Traded Fund') |\n",
    "                       ddf['fund_name'].str.contains('Vanguard', na=False)]\n",
    "    \n",
    "    # Compute and write the result to a new CSV file\n",
    "    filtered_ddf.compute().to_csv(output_file, index=False)\n",
    "    print(f\"Filtered data has been saved to {output_file}\")\n",
    "\n",
    "# Usage\n",
    "input_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv'  # Update this path to your actual CSV file path\n",
    "output_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/etf_merged_holdings.csv'  # Update this path to where you want the filtered data saved\n",
    "filter_and_export_csv_dask(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum up etf ownership of each stock on a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/etf_merged_holdings.csv\")\n",
    "\n",
    "# Group by 'stock_RIC' and 'date', and sum the 'stock_value_held'\n",
    "grouped_df = df.groupby(['stock_RIC', 'date'])['stock_value_held'].sum().reset_index()\n",
    "\n",
    "# Export to new CSV\n",
    "file_path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_etf_holdings_600_.csv\"\n",
    "grouped_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fund ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/dask/dataframe/io/csv.py:195: DtypeWarning: Columns (1,2,3,4,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to /Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/fund_ex_merged_holdings.csv\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def filter_and_export_csv_dask(input_file, output_file):\n",
    "    # Read the file using Dask\n",
    "    ddf = dd.read_csv(input_file)\n",
    "\n",
    "    # Drop rows with NaN in 'fund_type' or 'fund_name'\n",
    "    ddf = ddf.dropna(subset=['fund_type', 'fund_name'])\n",
    "    \n",
    "    # Apply filtering conditions\n",
    "    filtered_ddf = ddf[(ddf['fund_type'] != 'Exchange-Traded Fund') |\n",
    "                        ddf['fund_name'].str.contains('Vanguard') == False]\n",
    "    \n",
    "    # Compute and write the result to a new CSV file\n",
    "    filtered_ddf.compute().to_csv(output_file, index=False)\n",
    "    print(f\"Filtered data has been saved to {output_file}\")\n",
    "\n",
    "# Usage\n",
    "input_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_holdings.csv'  # Update this path to your actual CSV file path\n",
    "output_file = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/fund_ex_merged_holdings.csv'  # Update this path to where you want the filtered data saved\n",
    "filter_and_export_csv_dask(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum up fund ex etf ownership of each stock on a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = pd.read_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/fund_ex_merged_holdings.csv\")\n",
    "\n",
    "# Group by 'stock_RIC' and 'date', and sum the 'stock_value_held'\n",
    "grouped_df = df.groupby(['stock_RIC', 'date'])['stock_value_held'].sum().reset_index()\n",
    "\n",
    "# Export to new CSV\n",
    "file_path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_fund_ex_holdings_600_.csv\"\n",
    "grouped_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge etf and fund ownership with index membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data has been saved to /Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/formated_constituents_stoxx_europe_600.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(file1, file2, output_file):\n",
    "    # Read the CSV files into pandas DataFrames\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df2['date'] = pd.to_datetime(df2['date'])\n",
    "\n",
    "    # Perform the merge operation\n",
    "    merged_df = pd.merge(df1, df2, on=['date', 'stock_RIC'], how='left')\n",
    "\n",
    "    # Fill NA values in 'stock_value_held' with the desired placeholder if no match was found\n",
    "    merged_df['stock_value_held'].fillna('NA', inplace=True)\n",
    "\n",
    "    # Write the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Merged data has been saved to {output_file}\")\n",
    "\n",
    "# Usage\n",
    "formatted_index_member = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/formated_constituents_stoxx_europe_600.csv'\n",
    "file_etf_ownership = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_etf_holdings_600_.csv'\n",
    "file_fund_ownership = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/aggregated_fund_ex_holdings_600_.csv\"\n",
    "\n",
    "merge_csv_files(formatted_index_member, file_etf_ownership, formatted_index_member)\n",
    "#merge_csv_files(formatted_index_member, file_fund_ownership, formatted_index_member)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
