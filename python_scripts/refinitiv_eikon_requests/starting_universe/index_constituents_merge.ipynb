{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def merge_files(xlsx_dir, output_file_path):\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through all the files in the directory\n",
    "    for file_name in os.listdir(xlsx_dir):\n",
    "        if file_name.endswith('.xlsx'):\n",
    "            file_path = os.path.join(xlsx_dir, file_name)\n",
    "            \n",
    "            # Read the .xlsx file, assuming date is in cell B2 (second row, second column)\n",
    "            date_cell = pd.read_excel(file_path, header=None, usecols=\"B\", skiprows=1, nrows=1).iloc[0, 0]\n",
    "            # Parse the date string to a datetime object and reformat it\n",
    "            date_obj = datetime.strptime(date_cell, '%d-%b-%Y')\n",
    "            formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Read the rest of the .xlsx file, skipping the first two rows (header and date)\n",
    "            df = pd.read_excel(file_path, skiprows=2)\n",
    "            df['date'] = formatted_date\n",
    "\n",
    "            ########\n",
    "            merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "    # Rename columns as required\n",
    "    merged_df.columns = [\"stock_RIC\", \"stock_name\", \"country\", \"weight\", \"shares\", \"change\", \"date\"]\n",
    "    # Remove duplicates based on stock_name\n",
    "    unique_df = merged_df.drop_duplicates(subset='stock_name')\n",
    "\n",
    "    # Write to the specified output file path\n",
    "    unique_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOXX Europe 50 & 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>country</th>\n",
       "      <th>weight</th>\n",
       "      <th>shares</th>\n",
       "      <th>change</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RIC</td>\n",
       "      <td>Name</td>\n",
       "      <td>Country</td>\n",
       "      <td>Weight</td>\n",
       "      <td>No. Shares</td>\n",
       "      <td>Change</td>\n",
       "      <td>2020-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXAF.PA</td>\n",
       "      <td>AXA SA ORD</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>95944</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGEF.PA</td>\n",
       "      <td>VINCI SA ORD</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>25741</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DGE.L</td>\n",
       "      <td>DIAGEO PLC ORD</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>108345</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASML.AS</td>\n",
       "      <td>ASML HOLDING NV ORD</td>\n",
       "      <td>NETHERLANDS</td>\n",
       "      <td>0.035946</td>\n",
       "      <td>19737</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745</th>\n",
       "      <td>ABI.BR</td>\n",
       "      <td>ANHEUSER-BUSCH INBEV SA ORD</td>\n",
       "      <td>BELGIUM</td>\n",
       "      <td>0.02362</td>\n",
       "      <td>120714</td>\n",
       "      <td>-365</td>\n",
       "      <td>2015-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8746</th>\n",
       "      <td>BAYGn.DE</td>\n",
       "      <td>BAYER AG ORD</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>0.029462</td>\n",
       "      <td>129580</td>\n",
       "      <td>-760</td>\n",
       "      <td>2015-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8747</th>\n",
       "      <td>BASFn.DE</td>\n",
       "      <td>BASF SE ORD</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>0.021621</td>\n",
       "      <td>144243</td>\n",
       "      <td>-503</td>\n",
       "      <td>2015-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8748</th>\n",
       "      <td>GLEN.L</td>\n",
       "      <td>GLENCORE PLC ORD</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>0.011022</td>\n",
       "      <td>1553937</td>\n",
       "      <td>-7056</td>\n",
       "      <td>2015-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8749</th>\n",
       "      <td>UBSG.S</td>\n",
       "      <td>UBS GROUP AG ORD</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>564696</td>\n",
       "      <td>-2283</td>\n",
       "      <td>2015-02-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8750 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stock_RIC                   stock_name         country    weight  \\\n",
       "0          RIC                         Name         Country    Weight   \n",
       "1      AXAF.PA                   AXA SA ORD          FRANCE  0.009833   \n",
       "2      SGEF.PA                 VINCI SA ORD          FRANCE  0.011388   \n",
       "3        DGE.L               DIAGEO PLC ORD  UNITED KINGDOM  0.020469   \n",
       "4      ASML.AS          ASML HOLDING NV ORD     NETHERLANDS  0.035946   \n",
       "...        ...                          ...             ...       ...   \n",
       "8745    ABI.BR  ANHEUSER-BUSCH INBEV SA ORD         BELGIUM   0.02362   \n",
       "8746  BAYGn.DE                 BAYER AG ORD         GERMANY  0.029462   \n",
       "8747  BASFn.DE                  BASF SE ORD         GERMANY  0.021621   \n",
       "8748    GLEN.L             GLENCORE PLC ORD     SWITZERLAND  0.011022   \n",
       "8749    UBSG.S             UBS GROUP AG ORD     SWITZERLAND  0.015211   \n",
       "\n",
       "          shares  change        date  \n",
       "0     No. Shares  Change  2020-07-31  \n",
       "1          95944       0  2020-07-31  \n",
       "2          25741       0  2020-07-31  \n",
       "3         108345       0  2020-07-31  \n",
       "4          19737       0  2020-07-31  \n",
       "...          ...     ...         ...  \n",
       "8745      120714    -365  2015-02-28  \n",
       "8746      129580    -760  2015-02-28  \n",
       "8747      144243    -503  2015-02-28  \n",
       "8748     1553937   -7056  2015-02-28  \n",
       "8749      564696   -2283  2015-02-28  \n",
       "\n",
       "[8750 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_files = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/stoxx_europe_50_raw_data'\n",
    "output_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/stoxx_europe_50_RIC_mapping.csv'\n",
    "merged_df_50 = merge_files(raw_files, output_file_path)\n",
    "\n",
    "display(merged_df_50)\n",
    "\n",
    "raw_files = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/stoxx_europe_600_raw_data'\n",
    "output_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/stoxx_europe_600_RIC_mapping.csv'\n",
    "merged_df_600 = merge_files(raw_files, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling misssing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def process_and_fill_dates(data, output_file_path):\n",
    "    # Ensure 'Date' column is in datetime format\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data.sort_values('date', inplace=True)\n",
    "\n",
    "    def fill_missing_months(data):\n",
    "        unique_dates = data['date'].unique()\n",
    "        min_date, max_date = min(unique_dates), max(unique_dates)\n",
    "        all_dates = pd.date_range(start=min_date, end=max_date, freq='M').to_series()  # Generate all possible months\n",
    "        \n",
    "        last_valid_data = None\n",
    "        results = []\n",
    "\n",
    "        # Loop through each month in the generated date range\n",
    "        for current_date in all_dates:\n",
    "            if current_date in unique_dates:\n",
    "                # If current month data is present, update last_valid_data\n",
    "                last_valid_data = data[data['date'] == current_date]\n",
    "            elif last_valid_data is not None:\n",
    "                # If no data for the current month, copy last valid data and change the date\n",
    "                temp_data = last_valid_data.copy()\n",
    "                temp_data['date'] = current_date\n",
    "                results.append(temp_data)\n",
    "            else:\n",
    "                # If no previous data is available (unlikely), continue without action\n",
    "                continue\n",
    "\n",
    "        # Concatenate all results with original data and re-sort\n",
    "        if results:\n",
    "            data = pd.concat([data] + results, ignore_index=True)\n",
    "            data.sort_values('date', inplace=True)\n",
    "\n",
    "        return data\n",
    "\n",
    "    # Apply the function to fill missing months\n",
    "    filled_data = fill_missing_months(data)\n",
    "    #display(filled_data)\n",
    "\n",
    "    ########## filled_data only keep rows that have weights\n",
    "    filled_data['weight'] = pd.to_numeric(filled_data['weight'], errors='coerce')\n",
    "    # Drop rows where 'weight' is NaN\n",
    "    filled_data = filled_data.dropna(subset=['weight'])\n",
    "    filled_data = filled_data.dropna(subset=['country'])\n",
    "    filled_data = filled_data[~filled_data['stock_name'].str.contains('CASH|FORWARD|LIABILITIES', na=False)]\n",
    "\n",
    "    ######## create ranking\n",
    "    filled_data['rank'] = filled_data.groupby('date')['weight'].rank(method='first', ascending=False)\n",
    "\n",
    "    filled_data.to_csv(output_file_path, index=False)\n",
    "    return filled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOXX Europe 50 & 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>country</th>\n",
       "      <th>weight</th>\n",
       "      <th>shares</th>\n",
       "      <th>change</th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [stock_RIC, stock_name, country, weight, shares, change, date, rank]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/stoxx_europe_50_index_proxi_merge.csv'\n",
    "subset_df = process_and_fill_dates(merged_df_50, output_file_path)\n",
    "\n",
    "output_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/stoxx_europe_600_index_proxi_merge.csv'\n",
    "process_and_fill_dates(merged_df_600, output_file_path)\n",
    "\n",
    "subset_df = subset_df.dropna()\n",
    "# subset_df = df[df['date'] == pd.Timestamp('2020-10-31')]\n",
    "duplicates = subset_df.duplicated(subset = [\"date\", \"stock_RIC\"])\n",
    "# display(subset_df)\n",
    "\n",
    "display(subset_df[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index member dummy variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_index_etf_data(index_proxi_merge, output_file_path):\n",
    "    # Load ETF and index data from specified paths\n",
    "    filled_data = pd.read_csv(index_proxi_merge)\n",
    "    df = filled_data[[\"stock_RIC\", \"stock_name\", \"date\"]]\n",
    "    rank_df = filled_data[['stock_RIC', 'date', 'rank']]\n",
    "    rank_df['date'] = pd.to_datetime(rank_df['date']).dt.date\n",
    "    \n",
    "    # Create a pivot table with 'stock_RIC' as columns and 'date' as rows\n",
    "    pivot_df = df.pivot_table(index='date', columns='stock_RIC', aggfunc='size', fill_value=0)\n",
    "    \n",
    "    # Convert pivot table to long format\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "    long_df = pivot_df.melt(id_vars=['date'], var_name='stock_RIC', value_name='member')\n",
    "    \n",
    "    # Adjust the 'member' column to be binary (1 if member, 0 if not)\n",
    "    long_df['member'] = (long_df['member'] > 0).astype(int)\n",
    "    long_df.columns = [\"date\", \"stock_RIC\", \"index_member\"]\n",
    "    long_df['date'] = pd.to_datetime(long_df['date']).dt.date\n",
    "\n",
    "\n",
    "    long_df = pd.merge(long_df, rank_df, on=['date', 'stock_RIC'], how='left')\n",
    "    display(long_df)\n",
    "    # Save the processed data to a specified output file path\n",
    "    long_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOXX Europe 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/n85vv59j4lj5g5nndc07m8t40000gn/T/ipykernel_42682/2527912050.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rank_df['date'] = pd.to_datetime(rank_df['date']).dt.date\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>index_member</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>AAL.L</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>AAL.L</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>AAL.L</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>AAL.L</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>AAL.L</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15283</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15284</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15286</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15287</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15288 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date stock_RIC  index_member  rank\n",
       "0      2010-01-31     AAL.L             1  30.0\n",
       "1      2010-02-28     AAL.L             1  31.0\n",
       "2      2010-03-31     AAL.L             1  21.0\n",
       "3      2010-04-30     AAL.L             1  21.0\n",
       "4      2010-05-31     AAL.L             1  20.0\n",
       "...           ...       ...           ...   ...\n",
       "15283  2023-08-31    ZURN.S             1  28.0\n",
       "15284  2023-09-30    ZURN.S             1  27.0\n",
       "15285  2023-10-31    ZURN.S             1  25.0\n",
       "15286  2023-11-30    ZURN.S             1  26.0\n",
       "15287  2023-12-31    ZURN.S             1  26.0\n",
       "\n",
       "[15288 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/n85vv59j4lj5g5nndc07m8t40000gn/T/ipykernel_42682/2527912050.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rank_df['date'] = pd.to_datetime(rank_df['date']).dt.date\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>index_member</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191683</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191684</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191685</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191686</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191687</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191688 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date stock_RIC  index_member  rank\n",
       "0       2010-01-31    0A5O.L             0   NaN\n",
       "1       2010-02-28    0A5O.L             0   NaN\n",
       "2       2010-03-31    0A5O.L             0   NaN\n",
       "3       2010-04-30    0A5O.L             0   NaN\n",
       "4       2010-05-31    0A5O.L             0   NaN\n",
       "...            ...       ...           ...   ...\n",
       "191683  2023-08-31    ZURN.S             1  28.0\n",
       "191684  2023-09-30    ZURN.S             1  27.0\n",
       "191685  2023-10-31    ZURN.S             1  25.0\n",
       "191686  2023-11-30    ZURN.S             1  27.0\n",
       "191687  2023-12-31    ZURN.S             1  26.0\n",
       "\n",
       "[191688 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_proxi_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/stoxx_europe_50_index_proxi_merge.csv'\n",
    "output_file_path  = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/STOXX_Europe_50/formated_constituents_stoxx_europe_50.csv\"\n",
    "process_index_etf_data(index_proxi_file_path, output_file_path)\n",
    "\n",
    "index_proxi_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/stoxx_europe_600_index_proxi_merge.csv'\n",
    "output_file_path  = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/STOXX_Europe_600/formated_constituents_stoxx_europe_600.csv\"\n",
    "process_index_etf_data(index_proxi_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge index membership 50 and 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_RIC</th>\n",
       "      <th>index_member_600</th>\n",
       "      <th>rank_600</th>\n",
       "      <th>index_member_50</th>\n",
       "      <th>rank_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>0A5O.L</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191683</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191684</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191685</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191686</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191687</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>ZURN.S</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191688 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date stock_RIC  index_member_600  rank_600  index_member_50  \\\n",
       "0       2010-01-31    0A5O.L                 0       NaN                0   \n",
       "1       2010-02-28    0A5O.L                 0       NaN                0   \n",
       "2       2010-03-31    0A5O.L                 0       NaN                0   \n",
       "3       2010-04-30    0A5O.L                 0       NaN                0   \n",
       "4       2010-05-31    0A5O.L                 0       NaN                0   \n",
       "...            ...       ...               ...       ...              ...   \n",
       "191683  2023-08-31    ZURN.S                 1      28.0                1   \n",
       "191684  2023-09-30    ZURN.S                 1      27.0                1   \n",
       "191685  2023-10-31    ZURN.S                 1      25.0                1   \n",
       "191686  2023-11-30    ZURN.S                 1      27.0                1   \n",
       "191687  2023-12-31    ZURN.S                 1      26.0                1   \n",
       "\n",
       "        rank_50  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "191683     28.0  \n",
       "191684     27.0  \n",
       "191685     25.0  \n",
       "191686     26.0  \n",
       "191687     26.0  \n",
       "\n",
       "[191688 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets from CSV files\n",
    "df_600 = pd.read_csv('/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/STOXX_Europe_600/formated_constituents_stoxx_europe_600.csv')\n",
    "df_50 = pd.read_csv('/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/STOXX_Europe_50/formated_constituents_stoxx_europe_50.csv')\n",
    "\n",
    "# Rename 'index_member' columns to differentiate them\n",
    "df_600.rename(columns={'index_member': 'index_member_600', 'rank': 'rank_600' }, inplace=True)\n",
    "df_50.rename(columns={'index_member': 'index_member_50', 'rank': 'rank_50'}, inplace=True)\n",
    "\n",
    "# Merge the two dataframes on 'date' and 'stock_RIC'\n",
    "merged_df = pd.merge(df_600, df_50, on=['date', 'stock_RIC'], how='left')\n",
    "\n",
    "# Fill missing 'index_member_50' values with 0\n",
    "merged_df['index_member_50'].fillna(0, inplace=True)\n",
    "merged_df['index_member_50'] = merged_df['index_member_50'].astype(int)  # Ensure it's an integer\n",
    "\n",
    "display(merged_df)\n",
    "merged_df.to_csv('/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/formated_constituents.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
