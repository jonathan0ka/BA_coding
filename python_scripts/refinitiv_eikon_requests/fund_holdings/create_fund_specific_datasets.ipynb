{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter ETFs, Index Funds and Active Funds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter_function\n",
    "This function loads merged_data.csv and assigns funds to one of the following categories: `ETF`, `index_fund`, `active_fund`. Further the function allows for a filter on the location of the fund.\n",
    "\n",
    "- Data Ingestion: Reads input CSV files in parallel with Dask.\n",
    "- Data Cleaning: Drops rows with missing values in essential columns (stock_RIC, fund_type, fund_name, percent_of_traded_shares).\n",
    "- Filtering: Filters data based on specified fund types (etf, mutual fund, index fund, active fund). Optionally restricts the data to European countries using a predefined country list.\n",
    "- Data Transformation: Adjusts the date column to the last day of the previous month for ETFs and mutual funds. Removes any unnamed columns and duplicates based on key identifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Optional\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def country_filter(ddf: dd.DataFrame, selected_countries: Optional[List[str]] = None) -> dd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the Dask DataFrame for the specified countries.\n",
    "\n",
    "    Parameters:\n",
    "    - ddf: Dask DataFrame to filter.\n",
    "    - selected_countries: List of country names to include. Defaults to European countries.\n",
    "\n",
    "    Returns:\n",
    "    - Filtered Dask DataFrame.\n",
    "    \"\"\"\n",
    "    if selected_countries is None:\n",
    "        selected_countries = [\n",
    "            \"Albania\", \"Andorra\", \"Armenia\", \"Austria\", \"Azerbaijan\", \"Belarus\", \"Belgium\",\n",
    "            \"Bosnia and Herzegovina\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
    "            \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Georgia\", \"Germany\", \"Greece\",\n",
    "            \"Hungary\", \"Iceland\", \"Ireland\", \"Italy\", \"Kazakhstan\", \"Kosovo\", \"Latvia\",\n",
    "            \"Liechtenstein\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Moldova\", \"Monaco\",\n",
    "            \"Montenegro\", \"Netherlands\", \"North Macedonia\", \"Norway\", \"Poland\", \"Portugal\",\n",
    "            \"Romania\", \"San Marino\", \"Serbia\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\",\n",
    "            \"Switzerland\", \"Turkey\", \"Ukraine\", \"United Kingdom\", \"Vatican City\"\n",
    "        ]\n",
    "    logging.info(\"Applying country filter...\")\n",
    "    return ddf[ddf['country'].isin(selected_countries)]\n",
    "\n",
    "def filter_function(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    fund_type: str = \"etf\",\n",
    "    subset: Optional[str] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Filters the input CSV based on fund type and subset, then writes the result to a CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - input_file: Path to the input CSV file.\n",
    "    - output_file: Path to the output CSV file.\n",
    "    - fund_type: Type of fund to filter ('etf', 'mutual fund', 'index fund', 'active fund').\n",
    "    - subset: Subset criteria (e.g., 'europe').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Reading input file: {input_file}\")\n",
    "        ddf = dd.read_csv(input_file)\n",
    "\n",
    "        # Drop rows with missing essential fields\n",
    "        logging.info(\"Dropping rows with missing values in essential columns...\")\n",
    "        essential_columns = [\"stock_RIC\", \"fund_type\", \"fund_name\", \"percent_of_traded_shares\"]\n",
    "        ddf = ddf.dropna(subset=essential_columns)\n",
    "\n",
    "        # Define filtering logic based on fund type\n",
    "        logging.info(f\"Filtering for fund type: {fund_type}\")\n",
    "        if fund_type == \"etf\":\n",
    "            filtered_ddf = ddf[ddf['fund_type'] == 'Exchange-Traded Fund']\n",
    "        elif fund_type == \"mutual fund\":\n",
    "            filtered_ddf = ddf[\n",
    "                ((ddf['fund_type'] != 'Exchange-Traded Fund') & ~ddf['fund_name'].str.contains('Vanguard', case=False, na=False)) |\n",
    "                ((ddf['fund_investment_type'] != 'Index') & (ddf['fund_type'] != 'Exchange-Traded Fund'))\n",
    "            ]\n",
    "        elif fund_type == \"index fund\":\n",
    "            filtered_ddf = ddf[ddf['fund_investment_type'] == 'Index']\n",
    "        elif fund_type == \"active fund\":\n",
    "            filtered_ddf = ddf[ddf['fund_investment_type'] != 'Index']\n",
    "        else:\n",
    "            logging.error(f\"Unsupported fund type: {fund_type}\")\n",
    "            return\n",
    "\n",
    "        # Apply country filter if subset is specified\n",
    "        if subset == \"europe\":\n",
    "            filtered_ddf = country_filter(filtered_ddf)\n",
    "\n",
    "        # Persist the filtered Dask DataFrame in memory\n",
    "        logging.info(\"Persisting filtered data in memory...\")\n",
    "        filtered_ddf = filtered_ddf.persist()\n",
    "\n",
    "        # Perform transformations with Dask\n",
    "        if fund_type in [\"etf\", \"mutual fund\"]:\n",
    "            logging.info(\"Processing date column...\")\n",
    "            filtered_ddf['date'] = dd.to_datetime(filtered_ddf['date'], errors='coerce')\n",
    "            filtered_ddf['date'] = filtered_ddf['date'] - pd.offsets.MonthEnd(1)\n",
    "\n",
    "        # Drop unnamed columns\n",
    "        logging.info(\"Cleaning DataFrame by dropping unnamed columns and duplicates...\")\n",
    "        df_clean = filtered_ddf.loc[:, ~filtered_ddf.columns.str.contains('Unnamed')]\n",
    "        df_clean = df_clean.drop_duplicates(subset=['stock_RIC', 'fund_name', 'date', 'percent_of_traded_shares'], keep='first')\n",
    "\n",
    "        # write to CSV\n",
    "        logging.info(f\"Writing filtered data to output file: {output_file}\")\n",
    "        df_clean.to_csv(output_file, single_file=True, index=False)\n",
    "        logging.info(\"Filter function completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in filter_function: {e}\")\n",
    "\n",
    "def aggregation_function(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    fund_type: str = \"etf\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Aggregates the input CSV by 'stock_RIC' and 'date', summing specified columns, and writes to CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - input_file: Path to the input CSV file.\n",
    "    - output_file: Path to the output CSV file.\n",
    "    - fund_type: Type of fund for renaming columns ('mutual fund', 'index fund', 'active fund').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Reading input file for aggregation: {input_file}\")\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        logging.info(\"Grouping and aggregating data...\")\n",
    "        grouped_df = df.groupby(['stock_RIC', 'date'])[['stock_value_held', \"percent_of_traded_shares\"]].sum().reset_index()\n",
    "\n",
    "        # Rename columns based on fund type\n",
    "        rename_mapping = {}\n",
    "        if fund_type == \"mutual fund\":\n",
    "            rename_mapping = {\n",
    "                'stock_value_held': 'FUND_stock_value_held',\n",
    "                'percent_of_traded_shares': 'FUND_percent_of_traded_shares'\n",
    "            }\n",
    "        elif fund_type == \"index fund\":\n",
    "            rename_mapping = {\n",
    "                'stock_value_held': 'INDEX_FUND_stock_value_held',\n",
    "                'percent_of_traded_shares': 'INDEX_FUND_percent_of_traded_shares'\n",
    "            }\n",
    "        elif fund_type == \"active fund\":\n",
    "            rename_mapping = {\n",
    "                'stock_value_held': 'ACTIVE_FUND_stock_value_held',\n",
    "                'percent_of_traded_shares': 'ACTIVE_FUND_percent_of_traded_shares'\n",
    "            }\n",
    "        else:\n",
    "            logging.warning(f\"Unknown fund type '{fund_type}'. Columns will not be renamed.\")\n",
    "\n",
    "        if rename_mapping:\n",
    "            grouped_df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "        logging.info(f\"Writing aggregated data to output file: {output_file}\")\n",
    "        grouped_df.to_csv(output_file, index=False)\n",
    "        logging.info(\"Aggregation function completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in aggregation_function: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Configuration dictionary for file paths and parameters\n",
    "    config = {\n",
    "        \"input_file\": '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/merged_data.csv',\n",
    "        \"output_dir\": '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/fund_type_filtered',\n",
    "        \"subset\": \"europe\",\n",
    "        \"fund_types\": [\"etf\", \"mutual fund\", \"index fund\", \"active fund\"]\n",
    "    }\n",
    "\n",
    "    os.makedirs(config[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "    # ETF Filtering\n",
    "    filter_function(\n",
    "        input_file=config[\"input_file\"],\n",
    "        output_file=os.path.join(config[\"output_dir\"], \"etf_data_europe_van.csv\"),\n",
    "        fund_type=\"etf\",\n",
    "        subset=config[\"subset\"]\n",
    "    )\n",
    "\n",
    "    # Mutual Fund Filtering\n",
    "    filter_function(\n",
    "        input_file=config[\"input_file\"],\n",
    "        output_file=os.path.join(config[\"output_dir\"], \"fund_data_europe_van.csv\"),\n",
    "        fund_type=\"mutual fund\",\n",
    "        subset=config[\"subset\"]\n",
    "    )\n",
    "\n",
    "    # Index Fund Filtering\n",
    "    filter_function(\n",
    "        input_file=os.path.join(config[\"output_dir\"], \"fund_data_europe_van.csv\"),\n",
    "        output_file=os.path.join(config[\"output_dir\"], \"index_fund_data_europe_van.csv\"),\n",
    "        fund_type=\"index fund\",\n",
    "        subset=config[\"subset\"]\n",
    "    )\n",
    "\n",
    "    # Active Fund Filtering\n",
    "    filter_function(\n",
    "        input_file=os.path.join(config[\"output_dir\"], \"fund_data_europe_van.csv\"),\n",
    "        output_file=os.path.join(config[\"output_dir\"], \"active_fund_data_europe_van.csv\"),\n",
    "        fund_type=\"active fund\",\n",
    "        subset=config[\"subset\"]\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
