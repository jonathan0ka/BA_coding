{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge aggregated ETF and Fund ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def aggregation_function(input_file: str, output_file: str, fund_type: str = \"etf\") -> None:\n",
    "    \"\"\"\n",
    "    Aggregates the input CSV by 'stock_RIC' and 'date', summing specified columns, and writes to CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - input_file: Path to the input CSV file.\n",
    "    - output_file: Path to the output CSV file.\n",
    "    - fund_type: Type of fund for renaming columns ('etf', 'mutual fund', 'index fund', 'active fund').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Aggregating data from {input_file} for fund type: {fund_type}\")\n",
    "        df = pd.read_csv(input_file, index_col=False)\n",
    "\n",
    "        # Group by 'stock_RIC' and 'date' and sum the relevant columns\n",
    "        grouped_df = df.groupby(['stock_RIC', 'date'])[['stock_value_held', 'percent_of_traded_shares']].sum().reset_index()\n",
    "\n",
    "        # Define renaming mappings based on fund type\n",
    "        renaming_mappings = {\n",
    "            \"etf\": {\n",
    "                'stock_value_held': 'ETF_stock_value_held',\n",
    "                'percent_of_traded_shares': 'ETF_percent_of_traded_shares'\n",
    "            },\n",
    "            \"mutual fund\": {\n",
    "                'stock_value_held': 'FUND_stock_value_held',\n",
    "                'percent_of_traded_shares': 'FUND_percent_of_traded_shares'\n",
    "            },\n",
    "            \"index fund\": {\n",
    "                'stock_value_held': 'INDEX_FUND_stock_value_held',\n",
    "                'percent_of_traded_shares': 'INDEX_FUND_percent_of_traded_shares'\n",
    "            },\n",
    "            \"active fund\": {\n",
    "                'stock_value_held': 'ACTIVE_FUND_stock_value_held',\n",
    "                'percent_of_traded_shares': 'ACTIVE_FUND_percent_of_traded_shares'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Apply renaming if the fund type is recognized\n",
    "        if fund_type in renaming_mappings:\n",
    "            grouped_df.rename(columns=renaming_mappings[fund_type], inplace=True)\n",
    "            logging.info(f\"Renamed columns for fund type: {fund_type}\")\n",
    "        else:\n",
    "            logging.warning(f\"Unknown fund type '{fund_type}'. Columns will not be renamed.\")\n",
    "\n",
    "        # Save the aggregated DataFrame to the output CSV\n",
    "        grouped_df.to_csv(output_file, index=False)\n",
    "        logging.info(f\"Aggregated data saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in aggregation_function for {input_file}: {e}\")\n",
    "\n",
    "def merge_csv_files(file1: str, file2: str, output_file: str, columns_to_add: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Merges two CSV files on 'date' and 'stock_RIC', adds specified columns, and writes the result to a new CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - file1: Path to the first input CSV file.\n",
    "    - file2: Path to the second input CSV file.\n",
    "    - output_file: Path to the output CSV file.\n",
    "    - columns_to_add: List of column names to add from the second CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Merging {file1} with {file2}, adding columns: {columns_to_add}\")\n",
    "        df1 = pd.read_csv(file1)\n",
    "        df2 = pd.read_csv(file2)\n",
    "\n",
    "        key_columns = ['date', 'stock_RIC']\n",
    "\n",
    "        # Ensure 'date' columns are datetime objects\n",
    "        df1['date'] = pd.to_datetime(df1['date'], errors='coerce')\n",
    "        df2['date'] = pd.to_datetime(df2['date'], errors='coerce')\n",
    "\n",
    "        # Select only the key columns and columns to add from df2\n",
    "        cols_to_keep = key_columns + columns_to_add\n",
    "        df2_subset = df2[cols_to_keep]\n",
    "\n",
    "        # Merge df1 with df2_subset on 'date' and 'stock_RIC'\n",
    "        merged_df = pd.merge(df1, df2_subset, on=key_columns, how='left')\n",
    "\n",
    "        # Fill NA values in the added columns with 'NA'\n",
    "        for col in columns_to_add:\n",
    "            merged_df[col].fillna('NA', inplace=True)\n",
    "\n",
    "        # Save the merged DataFrame to the output CSV\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        logging.info(f\"Merged data saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error merging {file1} and {file2}: {e}\")\n",
    "\n",
    "def apply_merge_function(subset: str = \"none\") -> None:\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Applying merge function with subset: {subset}\")\n",
    "\n",
    "        # Define file paths based on subset\n",
    "        base_dir = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data'\n",
    "        aggregated_dir = os.path.join(base_dir, 'fund_holdings_data', 'aggregated_data')\n",
    "        final_dir = os.path.join(base_dir, 'fund_holdings_data')\n",
    "\n",
    "        if subset == \"europe\":\n",
    "            aggregated_files = {\n",
    "                \"etf\": os.path.join(aggregated_dir, \"etf_aggregated_data_europe.csv\"),\n",
    "                \"mutual_fund\": os.path.join(aggregated_dir, \"fund_aggregated_data_europe.csv\"),\n",
    "                \"index_fund\": os.path.join(aggregated_dir, \"index_fund_aggregated_data_europe.csv\"),\n",
    "                \"active_fund\": os.path.join(aggregated_dir, \"active_fund_aggregated_data_europe.csv\")\n",
    "            }\n",
    "            output_file = os.path.join(final_dir, \"formatted_final_europe_van.csv\")\n",
    "        else:\n",
    "            aggregated_files = {\n",
    "                \"etf\": os.path.join(aggregated_dir, \"etf_aggregated_data.csv\"),\n",
    "                \"mutual_fund\": os.path.join(aggregated_dir, \"fund_aggregated_data.csv\"),\n",
    "                \"index_fund\": os.path.join(aggregated_dir, \"index_fund_aggregated_data.csv\"),\n",
    "                \"active_fund\": os.path.join(aggregated_dir, \"active_fund_aggregated_data.csv\")\n",
    "            }\n",
    "            output_file = os.path.join(final_dir, \"formatted_final_van.csv\")\n",
    "\n",
    "        # Paths to index members and stock level data\n",
    "        formatted_index_member = os.path.join(base_dir, 'index_constituents_data', 'formated_constituents.csv')\n",
    "        file_m_stock = os.path.join(base_dir, 'stock_level_data', 'm_stock_level_data.csv')\n",
    "\n",
    "        merge_csv_files(\n",
    "            file1=formatted_index_member,\n",
    "            file2=aggregated_files[\"etf\"],\n",
    "            output_file=output_file,\n",
    "            columns_to_add=['ETF_stock_value_held', 'ETF_percent_of_traded_shares']\n",
    "        )\n",
    "\n",
    "        merge_csv_files(\n",
    "            file1=output_file,\n",
    "            file2=aggregated_files[\"mutual_fund\"],\n",
    "            output_file=output_file,\n",
    "            columns_to_add=[\"FUND_stock_value_held\", \"FUND_percent_of_traded_shares\"]\n",
    "        )\n",
    "\n",
    "        merge_csv_files(\n",
    "            file1=output_file,\n",
    "            file2=aggregated_files[\"index_fund\"],\n",
    "            output_file=output_file,\n",
    "            columns_to_add=[\"INDEX_FUND_stock_value_held\", \"INDEX_FUND_percent_of_traded_shares\"]\n",
    "        )\n",
    "\n",
    "        merge_csv_files(\n",
    "            file1=output_file,\n",
    "            file2=aggregated_files[\"active_fund\"],\n",
    "            output_file=output_file,\n",
    "            columns_to_add=[\"ACTIVE_FUND_stock_value_held\", \"ACTIVE_FUND_percent_of_traded_shares\"]\n",
    "        )\n",
    "\n",
    "        merge_csv_files(\n",
    "            file1=output_file,\n",
    "            file2=file_m_stock,\n",
    "            output_file=output_file,\n",
    "            columns_to_add=['market_cap']\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Final merged data saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in apply_merge_function: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Configuration dictionary for file paths and parameters\n",
    "    config = {\n",
    "        \"base_dir\": '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data',\n",
    "        \"input_file\": os.path.join('/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data', 'merged_data.csv'),\n",
    "        \"filtered_dir\": os.path.join('/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data', 'fund_type_filtered'),\n",
    "        \"aggregated_dir\": os.path.join('/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data', 'aggregated_data'),\n",
    "        \"final_dir\": os.path.join('/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data'),\n",
    "        \"subset\": \"europe\",  # Change to \"none\" if no subset filtering is needed\n",
    "        \"fund_types\": [\"etf\", \"mutual fund\", \"index fund\", \"active fund\"]\n",
    "    }\n",
    "\n",
    "    aggregation_tasks = [\n",
    "        {\"type\": \"etf\", \"filtered\": \"none\"},\n",
    "        {\"type\": \"etf\", \"filtered\": \"europe\"},\n",
    "        {\"type\": \"mutual fund\", \"filtered\": \"none\"},\n",
    "        {\"type\": \"mutual fund\", \"filtered\": \"europe\"},\n",
    "        {\"type\": \"index fund\", \"filtered\": \"none\"},\n",
    "        {\"type\": \"index fund\", \"filtered\": \"europe\"},\n",
    "        {\"type\": \"active fund\", \"filtered\": \"none\"},\n",
    "        {\"type\": \"active fund\", \"filtered\": \"europe\"},\n",
    "    ]\n",
    "\n",
    "    # Perform aggregation for each task\n",
    "    for task in aggregation_tasks:\n",
    "        fund_type = task[\"type\"]\n",
    "        subset = task[\"filtered\"]\n",
    "\n",
    "        # Determine input and output file paths based on subset\n",
    "        if fund_type == \"etf\":\n",
    "            input_filename = \"etf_data_van.csv\" if subset == \"none\" else \"etf_data_europe_van.csv\"\n",
    "            output_filename = f\"etf_aggregated_data{'_europe' if subset == 'europe' else ''}.csv\"\n",
    "        elif fund_type == \"mutual fund\":\n",
    "            input_filename = \"fund_data_van.csv\" if subset == \"none\" else \"fund_data_europe_van.csv\"\n",
    "            output_filename = f\"fund_aggregated_data{'_europe' if subset == 'europe' else ''}.csv\"\n",
    "        elif fund_type == \"index fund\":\n",
    "            input_filename = \"index_fund_data_van.csv\" if subset == \"none\" else \"index_fund_data_europe_van.csv\"\n",
    "            output_filename = f\"index_fund_aggregated_data{'_europe' if subset == 'europe' else ''}.csv\"\n",
    "        elif fund_type == \"active fund\":\n",
    "            input_filename = \"active_fund_data_van.csv\" if subset == \"none\" else \"active_fund_data_europe_van.csv\"\n",
    "            output_filename = f\"active_fund_aggregated_data{'_europe' if subset == 'europe' else ''}.csv\"\n",
    "        else:\n",
    "            logging.warning(f\"Unknown fund type: {fund_type}. Skipping aggregation.\")\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(config[\"filtered_dir\"], input_filename)\n",
    "        output_path = os.path.join(config[\"aggregated_dir\"], output_filename)\n",
    "\n",
    "        aggregation_function(input_file=input_path, output_file=output_path, fund_type=fund_type)\n",
    "\n",
    "    apply_merge_function(subset=config[\"subset\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ownership percentage based on market capitalization held by the fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_ownership_percentage(subset = \"none\"):\n",
    "    output_file = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/formatted_final_van.csv\"\n",
    "    if subset == \"europe\":\n",
    "        output_file = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/fund_holdings_data/formatted_final_europe_van.csv\"\n",
    "    \n",
    "    df = pd.read_csv(output_file, index_col=False)\n",
    "    df['ETF_ownership'] = (df[\"stock_value_held\"] * 1_000_000)/ df[\"market_cap\"]\n",
    "    df['FUND_ownership'] = (df[\"FUND_stock_value_held\"] * 1_000_000)/ df[\"market_cap\"]\n",
    "    df['INDEX_FUND_ownership'] = (df[\"INDEX_FUND_stock_value_held\"] * 1_000_000)/ df[\"market_cap\"]\n",
    "    df['ACTIVE_FUND_ownership'] = (df[\"ACTIVE_FUND_stock_value_held\"] * 1_000_000)/ df[\"market_cap\"]\n",
    "    df.to_csv(output_file, index=False)\n",
    "    display(df)\n",
    "\n",
    "calculate_ownership_percentage(subset = \"none\")\n",
    "calculate_ownership_percentage(subset = \"europe\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
