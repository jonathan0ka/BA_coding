{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index constituents merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#3\n",
    "# Paths to the CSV files\n",
    "csv_file_path1 = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600.csv'\n",
    "csv_file_path2 = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_v2.csv'\n",
    "csv_file_path3 = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_v3.csv'\n",
    "csv_file_path4 = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_v4.csv'\n",
    "output_file_path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_merge.csv\"\n",
    "\n",
    "# Read CSV file\n",
    "df1 = pd.read_csv(csv_file_path1)\n",
    "df2 = pd.read_csv(csv_file_path2)\n",
    "df3 = pd.read_csv(csv_file_path3)\n",
    "df4 = pd.read_csv(csv_file_path4)\n",
    "\n",
    "appended_df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "appended_df.columns = [\"stock_RIC\", \"stock_name\", \"date\"]\n",
    "# Save the appended DataFrame to a new CSV file\n",
    "appended_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all the csv files to one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No engine for filetype: 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1111\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[0;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1111\u001b[0m     engine \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_option(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mio.excel.\u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m.writer\u001b[39m\u001b[39m\"\u001b[39m, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1112\u001b[0m     \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/_config/config.py:261\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__func__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/_config/config.py:135\u001b[0m, in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_option\u001b[39m(pat: \u001b[39mstr\u001b[39m, silent: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 135\u001b[0m     key \u001b[39m=\u001b[39m _get_single_key(pat, silent)\n\u001b[1;32m    137\u001b[0m     \u001b[39m# walk the nested dict\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/_config/config.py:121\u001b[0m, in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    120\u001b[0m         _warn_if_deprecated(pat)\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mraise\u001b[39;00m OptionError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such keys(s): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(pat)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(keys) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mOptionError\u001b[0m: No such keys(s): 'io.excel.csv.writer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/stoxx_europe_600_consituents/etf_constituents_merge.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/stoxx_europe_600_consituents/etf_constituents_merge.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m unique_df \u001b[39m=\u001b[39m merged_df\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstock_name\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/stoxx_europe_600_consituents/etf_constituents_merge.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m output_file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/RIC_mapping.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/python_scripts/refinitiv_eikon_requests/stoxx_europe_600_consituents/etf_constituents_merge.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m unique_df\u001b[39m.\u001b[39mto_excel(output_file_path, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:2252\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options)\u001b[0m\n\u001b[1;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcel\u001b[39;00m \u001b[39mimport\u001b[39;00m ExcelFormatter\n\u001b[1;32m   2241\u001b[0m formatter \u001b[39m=\u001b[39m ExcelFormatter(\n\u001b[1;32m   2242\u001b[0m     df,\n\u001b[1;32m   2243\u001b[0m     na_rep\u001b[39m=\u001b[39mna_rep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2250\u001b[0m     inf_rep\u001b[39m=\u001b[39minf_rep,\n\u001b[1;32m   2251\u001b[0m )\n\u001b[0;32m-> 2252\u001b[0m formatter\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m   2253\u001b[0m     excel_writer,\n\u001b[1;32m   2254\u001b[0m     sheet_name\u001b[39m=\u001b[39msheet_name,\n\u001b[1;32m   2255\u001b[0m     startrow\u001b[39m=\u001b[39mstartrow,\n\u001b[1;32m   2256\u001b[0m     startcol\u001b[39m=\u001b[39mstartcol,\n\u001b[1;32m   2257\u001b[0m     freeze_panes\u001b[39m=\u001b[39mfreeze_panes,\n\u001b[1;32m   2258\u001b[0m     engine\u001b[39m=\u001b[39mengine,\n\u001b[1;32m   2259\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[1;32m   2260\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/formats/excel.py:934\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[1;32m    930\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    932\u001b[0m     \u001b[39m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[1;32m    933\u001b[0m     \u001b[39m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m     writer \u001b[39m=\u001b[39m ExcelWriter(  \u001b[39m# type: ignore[abstract]\u001b[39;00m\n\u001b[1;32m    935\u001b[0m         writer, engine\u001b[39m=\u001b[39mengine, storage_options\u001b[39m=\u001b[39mstorage_options\n\u001b[1;32m    936\u001b[0m     )\n\u001b[1;32m    937\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1115\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[0;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m             engine \u001b[39m=\u001b[39m get_default_engine(ext, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwriter\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1114\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 1115\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo engine for filetype: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[39m# for mypy\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[39massert\u001b[39;00m engine \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: No engine for filetype: 'csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "xlsx_dir = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/raw_data'\n",
    "\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through all the files in the directory\n",
    "for file_name in os.listdir(xlsx_dir):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(xlsx_dir, file_name)\n",
    "        \n",
    "        # Read the .xlsx file, assuming date is in cell B2 (second row, second column)\n",
    "        date_cell = pd.read_excel(file_path, header=None, usecols=\"B\", skiprows=1, nrows=1).iloc[0, 0]\n",
    "        # Parse the date string to a datetime object and reformat it\n",
    "        date_obj = datetime.strptime(date_cell, '%d-%b-%Y')\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Read the rest of the .xlsx file, skipping the first two rows (header and date)\n",
    "        df = pd.read_excel(file_path, skiprows=2)\n",
    "        df['Date'] = formatted_date\n",
    "        \n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "merged_df.columns = [\"stock_RIC\", \"stock_name\", \"country\", \"weight\", \"shares\", \"change\", \"date\"]\n",
    "unique_df = merged_df.drop_duplicates(subset='stock_name')\n",
    "\n",
    "output_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/RIC_mapping.csv'\n",
    "unique_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0                        Unnamed: 1      Unnamed: 2  \\\n",
      "35370         EDFp.NXT      ELECTRICITE DE FRANCE SA ORD          FRANCE   \n",
      "35169            SDR.L                 SCHRODERS PLC ORD  UNITED KINGDOM   \n",
      "35170  SCVbSEK.xbo^F14                     SCANIA AB ORD          SWEDEN   \n",
      "35171           SCHP.S              SCHINDLER HOLDING AG     SWITZERLAND   \n",
      "35172            SVT.L              SEVERN TRENT PLC ORD  UNITED KINGDOM   \n",
      "...                ...                               ...             ...   \n",
      "24793           BNZL.L                     BUNZL PLC ORD  UNITED KINGDOM   \n",
      "24778            ABF.L  ASSOCIATED BRITISH FOODS PLC ORD  UNITED KINGDOM   \n",
      "24779         ATCOa.ST                ATLAS COPCO AB ORD          SWEDEN   \n",
      "24788          BICP.PA                SOCIETE BIC SA ORD          FRANCE   \n",
      "24598           SMWH.L                  WH SMITH PLC ORD  UNITED KINGDOM   \n",
      "\n",
      "      Unnamed: 3 Unnamed: 4 Unnamed: 5       Date  \n",
      "35370   0.002209      50425       9400 2010-01-31  \n",
      "35169   0.000363      22489       4192 2010-01-31  \n",
      "35170   0.000564      55989      10437 2010-01-31  \n",
      "35171   0.000536       8879       1559 2010-01-31  \n",
      "35172   0.000626      43026       8021 2010-01-31  \n",
      "...          ...        ...        ...        ...  \n",
      "24793   0.001152     230823      -2904 2017-04-30  \n",
      "24778   0.001443     247745      -3110 2017-04-30  \n",
      "24779   0.002657     443321      -5573 2017-04-30  \n",
      "24788   0.000334      18556       -240 2017-04-30  \n",
      "24598   0.000282      76999       -969 2017-04-30  \n",
      "\n",
      "[46173 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])  # Ensure 'Date' column is in datetime format\n",
    "\n",
    "merged_df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Function to fill missing months\n",
    "def fill_missing_months(data):\n",
    "    unique_dates = data['Date'].unique()  # Extract unique dates\n",
    "    min_date, max_date = min(unique_dates), max(unique_dates)\n",
    "    all_dates = pd.date_range(start=min_date, end=max_date, freq='M').to_series()  # Generate all possible months\n",
    "    \n",
    "    last_valid_data = None\n",
    "    results = []\n",
    "\n",
    "    # Loop through each month in the generated date range\n",
    "    for current_date in all_dates:\n",
    "        if current_date in unique_dates:\n",
    "            # If current month data is present, update last_valid_data\n",
    "            last_valid_data = data[data['Date'] == current_date]\n",
    "        elif last_valid_data is not None:\n",
    "            # If no data for the current month, copy last valid data and change the date\n",
    "            temp_data = last_valid_data.copy()\n",
    "            temp_data['Date'] = current_date\n",
    "            results.append(temp_data)\n",
    "        else:\n",
    "            # If no previous data is available (unlikely), continue without action\n",
    "            continue\n",
    "\n",
    "    # Concatenate all results with original data and re-sort\n",
    "    if results:\n",
    "        data = pd.concat([data] + results, ignore_index=True)\n",
    "        data.sort_values('Date', inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply the function to fill missing months\n",
    "filled_data = fill_missing_months(merged_df)\n",
    "filled_data.columns = [\"stock_RIC\", \"stock_name\", \"country\", \"weight\", \"shares\", \"change\", \"date\"]\n",
    "\n",
    "output_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/index_proxi_merge.csv'\n",
    "filled_data.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index member dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_data = filled_data[[\"stock_RIC\", \"stock_name\", \"date\"]]\n",
    "index_data = appended_df\n",
    "\n",
    "df = pd.concat([index_data, etf_data], ignore_index=True)\n",
    "\n",
    "# Create pivot table\n",
    "pivot_df = df.pivot_table(index='date', columns='stock_RIC', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Convert to long format\n",
    "pivot_df.reset_index(inplace=True)\n",
    "long_df = pivot_df.melt(id_vars=['date'], var_name='stock_RIC', value_name='member')\n",
    "\n",
    "# Adjust the 'member' column to be binary\n",
    "long_df['member'] = (long_df['member'] > 0).astype(int)\n",
    "\n",
    "long_df.columns = [\"date\", \"stock_RIC\", \"index_member\"]\n",
    "\n",
    "############\n",
    "long_df['date'] = pd.to_datetime(long_df['date'])\n",
    "long_df['date'] = long_df['date'].dt.date\n",
    "\n",
    "# Save to CSV (optional)\n",
    "file_path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/formated_constituents_stoxx_europe_600.csv\"\n",
    "long_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
