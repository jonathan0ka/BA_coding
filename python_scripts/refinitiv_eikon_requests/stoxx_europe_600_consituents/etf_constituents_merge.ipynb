{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index constituents merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#3\n",
    "# Paths to the CSV files\n",
    "csv_file_path1 = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600.csv'\n",
    "csv_file_path2 = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_v2.csv'\n",
    "csv_file_path3 = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_v3.csv'\n",
    "csv_file_path4 = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_v4.csv'\n",
    "output_file_path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_merge.csv\"\n",
    "\n",
    "# Read CSV file\n",
    "df1 = pd.read_csv(csv_file_path1)\n",
    "df2 = pd.read_csv(csv_file_path2)\n",
    "df3 = pd.read_csv(csv_file_path3)\n",
    "df4 = pd.read_csv(csv_file_path4)\n",
    "\n",
    "appended_df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "appended_df.columns = [\"stock_RIC\", \"stock_name\", \"date\"]\n",
    "# Save the appended DataFrame to a new CSV file\n",
    "appended_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all the csv files to one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "xlsx_dir = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/raw_data'\n",
    "\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through all the files in the directory\n",
    "for file_name in os.listdir(xlsx_dir):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(xlsx_dir, file_name)\n",
    "        \n",
    "        # Read the .xlsx file, assuming date is in cell B2 (second row, second column)\n",
    "        date_cell = pd.read_excel(file_path, header=None, usecols=\"B\", skiprows=1, nrows=1).iloc[0, 0]\n",
    "        # Parse the date string to a datetime object and reformat it\n",
    "        date_obj = datetime.strptime(date_cell, '%d-%b-%Y')\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Read the rest of the .xlsx file, skipping the first two rows (header and date)\n",
    "        df = pd.read_excel(file_path, skiprows=2)\n",
    "        df['Date'] = formatted_date\n",
    "        \n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "merged_df.columns = [\"stock_RIC\", \"stock_name\", \"country\", \"weight\", \"shares\", \"change\", \"date\"]\n",
    "unique_df = merged_df.drop_duplicates(subset='stock_name')\n",
    "\n",
    "output_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/RIC_mapping.xlsx'\n",
    "unique_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0                        Unnamed: 1      Unnamed: 2  \\\n",
      "35370         EDFp.NXT      ELECTRICITE DE FRANCE SA ORD          FRANCE   \n",
      "35169            SDR.L                 SCHRODERS PLC ORD  UNITED KINGDOM   \n",
      "35170  SCVbSEK.xbo^F14                     SCANIA AB ORD          SWEDEN   \n",
      "35171           SCHP.S              SCHINDLER HOLDING AG     SWITZERLAND   \n",
      "35172            SVT.L              SEVERN TRENT PLC ORD  UNITED KINGDOM   \n",
      "...                ...                               ...             ...   \n",
      "24793           BNZL.L                     BUNZL PLC ORD  UNITED KINGDOM   \n",
      "24778            ABF.L  ASSOCIATED BRITISH FOODS PLC ORD  UNITED KINGDOM   \n",
      "24779         ATCOa.ST                ATLAS COPCO AB ORD          SWEDEN   \n",
      "24788          BICP.PA                SOCIETE BIC SA ORD          FRANCE   \n",
      "24598           SMWH.L                  WH SMITH PLC ORD  UNITED KINGDOM   \n",
      "\n",
      "      Unnamed: 3 Unnamed: 4 Unnamed: 5       Date  \n",
      "35370   0.002209      50425       9400 2010-01-31  \n",
      "35169   0.000363      22489       4192 2010-01-31  \n",
      "35170   0.000564      55989      10437 2010-01-31  \n",
      "35171   0.000536       8879       1559 2010-01-31  \n",
      "35172   0.000626      43026       8021 2010-01-31  \n",
      "...          ...        ...        ...        ...  \n",
      "24793   0.001152     230823      -2904 2017-04-30  \n",
      "24778   0.001443     247745      -3110 2017-04-30  \n",
      "24779   0.002657     443321      -5573 2017-04-30  \n",
      "24788   0.000334      18556       -240 2017-04-30  \n",
      "24598   0.000282      76999       -969 2017-04-30  \n",
      "\n",
      "[46173 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])  # Ensure 'Date' column is in datetime format\n",
    "\n",
    "merged_df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Function to fill missing months\n",
    "def fill_missing_months(data):\n",
    "    unique_dates = data['Date'].unique()  # Extract unique dates\n",
    "    min_date, max_date = min(unique_dates), max(unique_dates)\n",
    "    all_dates = pd.date_range(start=min_date, end=max_date, freq='M').to_series()  # Generate all possible months\n",
    "    \n",
    "    last_valid_data = None\n",
    "    results = []\n",
    "\n",
    "    # Loop through each month in the generated date range\n",
    "    for current_date in all_dates:\n",
    "        if current_date in unique_dates:\n",
    "            # If current month data is present, update last_valid_data\n",
    "            last_valid_data = data[data['Date'] == current_date]\n",
    "        elif last_valid_data is not None:\n",
    "            # If no data for the current month, copy last valid data and change the date\n",
    "            temp_data = last_valid_data.copy()\n",
    "            temp_data['Date'] = current_date\n",
    "            results.append(temp_data)\n",
    "        else:\n",
    "            # If no previous data is available (unlikely), continue without action\n",
    "            continue\n",
    "\n",
    "    # Concatenate all results with original data and re-sort\n",
    "    if results:\n",
    "        data = pd.concat([data] + results, ignore_index=True)\n",
    "        data.sort_values('Date', inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply the function to fill missing months\n",
    "filled_data = fill_missing_months(merged_df)\n",
    "filled_data.columns = [\"stock_RIC\", \"stock_name\", \"country\", \"weight\", \"shares\", \"change\", \"date\"]\n",
    "\n",
    "output_file_path = '/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/index_proxi_merge.csv'\n",
    "filled_data.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index member dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/n85vv59j4lj5g5nndc07m8t40000gn/T/ipykernel_99549/2999787493.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows['date'] = pd.to_datetime(new_date)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filled_data = pd.read_csv('/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_proxi_data/index_proxi_merge.csv')\n",
    "etf_data = filled_data[[\"stock_RIC\", \"stock_name\", \"date\"]]\n",
    "index_data = pd.read_csv(\"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/constituents_stoxx_europe_600_merge.csv\")\n",
    "\n",
    "df = pd.concat([index_data, etf_data], ignore_index=True)\n",
    "\n",
    "# Create pivot table\n",
    "pivot_df = df.pivot_table(index='date', columns='stock_RIC', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Convert to long format\n",
    "pivot_df.reset_index(inplace=True)\n",
    "long_df = pivot_df.melt(id_vars=['date'], var_name='stock_RIC', value_name='member')\n",
    "\n",
    "# Adjust the 'member' column to be binary\n",
    "long_df['member'] = (long_df['member'] > 0).astype(int)\n",
    "\n",
    "long_df.columns = [\"date\", \"stock_RIC\", \"index_member\"]\n",
    "\n",
    "############\n",
    "long_df['date'] = pd.to_datetime(long_df['date'])\n",
    "long_df['date'] = long_df['date'].dt.date\n",
    "\n",
    "########################################## changing dates from end of month to start of next month\n",
    "def adjust_date_to_next_month_first(input_df, date_column):\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = input_df\n",
    "    # Ensure the date column is in datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "    # Adjust the date to the first day of the following month\n",
    "    df[date_column] = df[date_column] + pd.DateOffset(days=1)\n",
    "    df[date_column] = df[date_column] - pd.to_timedelta(df[date_column].dt.day - 1, unit='d')\n",
    "\n",
    "    # Write the updated DataFrame back to a new CSV file\n",
    "    return df\n",
    "    print(f\"Dates in column '{date_column}' have been adjusted and saved to {output_file}\")\n",
    "\n",
    "long_df = adjust_date_to_next_month_first(long_df, \"date\")\n",
    "\n",
    "##################################\n",
    "def modify_and_append_date(df, original_date, new_date):\n",
    "    selected_rows = df[df['date'] == pd.to_datetime(original_date)]\n",
    "\n",
    "    # Modify the date of these rows\n",
    "    selected_rows['date'] = pd.to_datetime(new_date)\n",
    "\n",
    "    # Append these rows back to the original DataFrame\n",
    "    return pd.concat([df, selected_rows])\n",
    "\n",
    "long_df = modify_and_append_date(long_df, \"2010-02-01\", \"2010-01-01\")\n",
    "long_df = long_df.sort_values(by=[\"stock_RIC\", \"date\"], ascending=True)\n",
    "# Save to CSV (optional)\n",
    "file_path = \"/Users/jonathanzeh/Library/CloudStorage/OneDrive-Personal/BA_Thesis/BA_coding/datasets/eikon_data/index_constituents_data/formated_constituents_stoxx_europe_600.csv\"\n",
    "long_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
